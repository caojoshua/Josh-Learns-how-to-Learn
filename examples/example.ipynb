{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import JoshLearnsHowToLearn as jll\n",
    "import numpy as np\n",
    "from sklearn import *\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caojo\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\caojo\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\caojo\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\caojo\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\caojo\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\caojo\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(999, 785)\n"
     ]
    }
   ],
   "source": [
    "data = np.genfromtxt(\"data/train_small.csv\", delimiter=\",\", skip_header=1, dtype=float)\n",
    "# data = data[:50]\n",
    "# data = np.genfromtxt(\"data/generated_dataset.csv\", delimiter=\",\", skip_header=1, dtype=float)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(999, 28, 28, 1)\n",
      "(999,)\n"
     ]
    }
   ],
   "source": [
    "X = data[:,1:]\n",
    "X = X.reshape((X.shape[0],28,28,1))\n",
    "Y = data[:,0]\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(999, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "X /= np.max(X)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(999, 10)\n"
     ]
    }
   ],
   "source": [
    "Y = Y.astype(dtype=int)\n",
    "tempY = np.zeros(shape=(len(Y), np.max(Y)+1))\n",
    "tempY[np.arange(len(Y)),Y] = 1\n",
    "Y = tempY\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train/validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(799, 28, 28, 1)\n",
      "(799, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caojo\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "Xtr, Xva, Ytr, Yva = model_selection.train_test_split(X, Y, train_size=.80, random_state=0)\n",
    "\n",
    "print(Xtr.shape)\n",
    "print(Ytr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = jll.NeuralNetwork.NeuralNetwork(input_shape = Xtr.shape[1:], lr=0.01, loss=jll.LossFunction.CrossEntropy())\n",
    "model.add_layer(jll.Layer.ConvolutionalLayer, filter_size = (2,2), num_filters = 8)\n",
    "model.add_layer(jll.Layer.Relu)\n",
    "model.add_layer(jll.Layer.ConvolutionalLayer, filter_size = (2,2), num_filters = 4)\n",
    "model.add_layer(jll.Layer.Relu)\n",
    "model.add_layer(jll.Layer.FlattenLayer)\n",
    "model.add_layer(jll.Layer.FullyConnectedLayer, num_neurons = 16)\n",
    "model.add_layer(jll.Layer.Relu)\n",
    "model.add_layer(jll.Layer.FullyConnectedLayer, num_neurons = 10)\n",
    "model.add_layer(jll.Layer.Softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch # 0 :\n",
      "\tTraining Accuracy:  0.37296620775969963\n",
      "\tValidation Accuracy:  0.365\n",
      "\tTraining loss:  1.7776297895960174\n",
      "\tvalidation loss:  1.7922098226917211\n",
      "epoch # 1 :\n",
      "\tTraining Accuracy:  0.6057571964956195\n",
      "\tValidation Accuracy:  0.62\n",
      "\tTraining loss:  1.2946964192908814\n",
      "\tvalidation loss:  1.2847141440579495\n",
      "epoch # 2 :\n",
      "\tTraining Accuracy:  0.655819774718398\n",
      "\tValidation Accuracy:  0.74\n",
      "\tTraining loss:  1.1494335749270748\n",
      "\tvalidation loss:  1.0890295950719746\n",
      "epoch # 3 :\n",
      "\tTraining Accuracy:  0.7221526908635795\n",
      "\tValidation Accuracy:  0.71\n",
      "\tTraining loss:  1.0286740202524398\n",
      "\tvalidation loss:  1.0393365234139285\n",
      "epoch # 4 :\n",
      "\tTraining Accuracy:  0.7797246558197747\n",
      "\tValidation Accuracy:  0.795\n",
      "\tTraining loss:  0.893380785958714\n",
      "\tvalidation loss:  0.8840483108080344\n",
      "epoch # 5 :\n",
      "\tTraining Accuracy:  0.7872340425531915\n",
      "\tValidation Accuracy:  0.79\n",
      "\tTraining loss:  0.8772316513960324\n",
      "\tvalidation loss:  0.8574749207051734\n",
      "epoch # 6 :\n",
      "\tTraining Accuracy:  0.7259073842302879\n",
      "\tValidation Accuracy:  0.76\n",
      "\tTraining loss:  0.8928731238952449\n",
      "\tvalidation loss:  0.9212813522228529\n",
      "epoch # 7 :\n",
      "\tTraining Accuracy:  0.8172715894868585\n",
      "\tValidation Accuracy:  0.805\n",
      "\tTraining loss:  0.7512619988678702\n",
      "\tvalidation loss:  0.7683805425418138\n",
      "epoch # 8 :\n",
      "\tTraining Accuracy:  0.8247809762202754\n",
      "\tValidation Accuracy:  0.83\n",
      "\tTraining loss:  0.7090656132992081\n",
      "\tvalidation loss:  0.7152114181525578\n",
      "epoch # 9 :\n",
      "\tTraining Accuracy:  0.7647058823529411\n",
      "\tValidation Accuracy:  0.745\n",
      "\tTraining loss:  0.7622339937663821\n",
      "\tvalidation loss:  0.7683314249642536\n",
      "epoch # 10 :\n",
      "\tTraining Accuracy:  0.8347934918648311\n",
      "\tValidation Accuracy:  0.835\n",
      "\tTraining loss:  0.5955171002600762\n",
      "\tvalidation loss:  0.5899864924227467\n",
      "epoch # 11 :\n",
      "\tTraining Accuracy:  0.6695869837296621\n",
      "\tValidation Accuracy:  0.66\n",
      "\tTraining loss:  0.9765712219615712\n",
      "\tvalidation loss:  1.0673065598004063\n",
      "epoch # 12 :\n",
      "\tTraining Accuracy:  0.8272841051314143\n",
      "\tValidation Accuracy:  0.82\n",
      "\tTraining loss:  0.6109152724074602\n",
      "\tvalidation loss:  0.5592647920959994\n",
      "epoch # 13 :\n",
      "\tTraining Accuracy:  0.523153942428035\n",
      "\tValidation Accuracy:  0.545\n",
      "\tTraining loss:  2.0608108337471926\n",
      "\tvalidation loss:  2.1198934755985417\n",
      "epoch # 14 :\n",
      "\tTraining Accuracy:  0.5807259073842302\n",
      "\tValidation Accuracy:  0.585\n",
      "\tTraining loss:  1.3649435900167313\n",
      "\tvalidation loss:  1.2440348061476119\n",
      "epoch # 15 :\n",
      "\tTraining Accuracy:  0.8272841051314143\n",
      "\tValidation Accuracy:  0.805\n",
      "\tTraining loss:  0.5861130808664555\n",
      "\tvalidation loss:  0.6488686329951073\n",
      "epoch # 16 :\n",
      "\tTraining Accuracy:  0.7521902377972466\n",
      "\tValidation Accuracy:  0.725\n",
      "\tTraining loss:  0.8224134593781594\n",
      "\tvalidation loss:  0.8360500507672416\n",
      "epoch # 17 :\n",
      "\tTraining Accuracy:  0.8585732165206508\n",
      "\tValidation Accuracy:  0.835\n",
      "\tTraining loss:  0.48242825438511083\n",
      "\tvalidation loss:  0.5082957992268852\n",
      "epoch # 18 :\n",
      "\tTraining Accuracy:  0.737171464330413\n",
      "\tValidation Accuracy:  0.725\n",
      "\tTraining loss:  0.7684008305206035\n",
      "\tvalidation loss:  0.7820880343318499\n",
      "epoch # 19 :\n",
      "\tTraining Accuracy:  0.8598247809762203\n",
      "\tValidation Accuracy:  0.815\n",
      "\tTraining loss:  0.46434099453139405\n",
      "\tvalidation loss:  0.4918262710235718\n"
     ]
    }
   ],
   "source": [
    "model.train(Xtr, Ytr, Xva, Yva, epochs=20, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_va = model.predict(Xva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 2 with 0.9969006191697893 confidence\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num = random.randint(0, len(Xva))\n",
    "plt.imshow(np.reshape(Xva[num], (28,28)))\n",
    "p = predict_va[num]\n",
    "max_index = np.argmax(p)\n",
    "print (\"Predicting\", max_index, \"with\", p[max_index], \"confidence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model = tf.keras.models.Sequential()\n",
    "tf_model.add(tf.layers.Conv2D(8, (2, 2), input_shape=(28, 28, 1),  activation=tf.nn.relu))\n",
    "tf_model.add(tf.layers.Conv2D(4, (2, 2),  activation=tf.nn.relu))\n",
    "tf_model.add(tf.layers.Flatten())\n",
    "tf_model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "tf_model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "tf_model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.01),\n",
    "                 loss = tf.keras.losses.categorical_crossentropy,\n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 799 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "799/799 [==============================] - 1s 967us/step - loss: 2.3200 - acc: 0.1089 - val_loss: 2.2991 - val_acc: 0.1500\n",
      "Epoch 2/20\n",
      "799/799 [==============================] - 0s 243us/step - loss: 2.2685 - acc: 0.1977 - val_loss: 2.2436 - val_acc: 0.2150\n",
      "Epoch 3/20\n",
      "799/799 [==============================] - 0s 220us/step - loss: 2.1974 - acc: 0.2753 - val_loss: 2.1434 - val_acc: 0.2950\n",
      "Epoch 4/20\n",
      "799/799 [==============================] - 0s 219us/step - loss: 2.0471 - acc: 0.3717 - val_loss: 1.9571 - val_acc: 0.4350\n",
      "Epoch 5/20\n",
      "799/799 [==============================] - 0s 231us/step - loss: 1.7907 - acc: 0.5344 - val_loss: 1.6344 - val_acc: 0.5400\n",
      "Epoch 6/20\n",
      "799/799 [==============================] - 0s 227us/step - loss: 1.4243 - acc: 0.6358 - val_loss: 1.2548 - val_acc: 0.6550\n",
      "Epoch 7/20\n",
      "799/799 [==============================] - 0s 231us/step - loss: 1.0806 - acc: 0.7159 - val_loss: 0.8320 - val_acc: 0.8000\n",
      "Epoch 8/20\n",
      "799/799 [==============================] - 0s 230us/step - loss: 0.8055 - acc: 0.7897 - val_loss: 0.8313 - val_acc: 0.7400\n",
      "Epoch 9/20\n",
      "799/799 [==============================] - 0s 229us/step - loss: 0.6979 - acc: 0.8160 - val_loss: 0.5624 - val_acc: 0.8300\n",
      "Epoch 10/20\n",
      "799/799 [==============================] - 0s 235us/step - loss: 0.5829 - acc: 0.8448 - val_loss: 0.5275 - val_acc: 0.8400\n",
      "Epoch 11/20\n",
      "799/799 [==============================] - 0s 231us/step - loss: 0.5407 - acc: 0.8461 - val_loss: 0.4744 - val_acc: 0.8550\n",
      "Epoch 12/20\n",
      "799/799 [==============================] - 0s 225us/step - loss: 0.4731 - acc: 0.8636 - val_loss: 0.5333 - val_acc: 0.8350\n",
      "Epoch 13/20\n",
      "799/799 [==============================] - 0s 239us/step - loss: 0.4481 - acc: 0.8723 - val_loss: 0.4339 - val_acc: 0.8700\n",
      "Epoch 14/20\n",
      "799/799 [==============================] - 0s 228us/step - loss: 0.4015 - acc: 0.8811 - val_loss: 0.5136 - val_acc: 0.8550\n",
      "Epoch 15/20\n",
      "799/799 [==============================] - 0s 228us/step - loss: 0.3893 - acc: 0.8936 - val_loss: 0.4439 - val_acc: 0.8500\n",
      "Epoch 16/20\n",
      "799/799 [==============================] - 0s 229us/step - loss: 0.3400 - acc: 0.9074 - val_loss: 0.4933 - val_acc: 0.8650\n",
      "Epoch 17/20\n",
      "799/799 [==============================] - 0s 232us/step - loss: 0.3387 - acc: 0.9049 - val_loss: 0.4225 - val_acc: 0.8800\n",
      "Epoch 18/20\n",
      "799/799 [==============================] - 0s 248us/step - loss: 0.2992 - acc: 0.9237 - val_loss: 0.4072 - val_acc: 0.8850\n",
      "Epoch 19/20\n",
      "799/799 [==============================] - 0s 246us/step - loss: 0.3004 - acc: 0.9124 - val_loss: 0.4826 - val_acc: 0.8550\n",
      "Epoch 20/20\n",
      "799/799 [==============================] - 0s 230us/step - loss: 0.2767 - acc: 0.9249 - val_loss: 0.4029 - val_acc: 0.8600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x26ed9708ac8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_model.fit(Xtr, Ytr, validation_data=(Xva, Yva), epochs = 20, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_predict_va = tf_model.predict(Xva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 6 with 0.98931944 confidence\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num = random.randint(0, len(Xva))\n",
    "plt.imshow(np.reshape(Xva[num], (28,28)))\n",
    "p = tf_predict_va[num]\n",
    "max_index = np.argmax(p)\n",
    "print (\"Predicting\", max_index, \"with\", p[max_index], \"confidence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
