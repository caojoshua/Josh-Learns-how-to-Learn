{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "    import imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import NeuralNetwork as nn\n",
    "import numpy as np\n",
    "from sklearn import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caojo\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\caojo\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\caojo\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\caojo\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\caojo\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\caojo\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(999, 785)\n"
     ]
    }
   ],
   "source": [
    "data = np.genfromtxt(\"data/train_small.csv\", delimiter=\",\", skip_header=1, dtype=float)\n",
    "# data = data[:50]\n",
    "# data = np.genfromtxt(\"data/generated_dataset.csv\", delimiter=\",\", skip_header=1, dtype=float)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(999, 784)\n",
      "(999,)\n"
     ]
    }
   ],
   "source": [
    "X = data[:,1:]\n",
    "Y = data[:,0]\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(999, 784)\n"
     ]
    }
   ],
   "source": [
    "X /= np.max(X)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(999, 10)\n"
     ]
    }
   ],
   "source": [
    "Y = Y.astype(dtype=int)\n",
    "tempY = np.zeros(shape=(len(Y), np.max(Y)+1))\n",
    "tempY[np.arange(len(Y)),Y] = 1\n",
    "Y = tempY\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train/validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(799, 784)\n",
      "(799, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caojo\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "Xtr, Xva, Ytr, Yva = model_selection.train_test_split(X, Y, train_size=.80, random_state=0)\n",
    "\n",
    "print(Xtr.shape)\n",
    "print(Ytr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.NeuralNetwork(input_length = Xtr.shape[1], lr=0.01, cost=nn.LossFunction.CrossEntropy())\n",
    "model.add_layer(nn.Layer.FullyConnectedLayer, num_neurons = 32)\n",
    "model.add_layer(nn.Layer.Relu)\n",
    "model.add_layer(nn.Layer.FullyConnectedLayer, num_neurons = 10)\n",
    "model.add_layer(nn.Layer.Softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch # 0 :\n",
      "\tTraining Accuracy:  0.1214017521902378\n",
      "\tTraining loss:  2.407921376844356\n",
      "epoch # 1 :\n",
      "\tTraining Accuracy:  0.1376720901126408\n",
      "\tTraining loss:  2.3669004516517997\n",
      "epoch # 2 :\n",
      "\tTraining Accuracy:  0.15269086357947434\n",
      "\tTraining loss:  2.3299745001877485\n",
      "epoch # 3 :\n",
      "\tTraining Accuracy:  0.16520650813516896\n",
      "\tTraining loss:  2.2956659238761996\n",
      "epoch # 4 :\n",
      "\tTraining Accuracy:  0.18773466833541927\n",
      "\tTraining loss:  2.270933630111109\n",
      "epoch # 5 :\n",
      "\tTraining Accuracy:  0.20775969962453067\n",
      "\tTraining loss:  2.2447180364484276\n",
      "epoch # 6 :\n",
      "\tTraining Accuracy:  0.22778473091364204\n",
      "\tTraining loss:  2.219706492135665\n",
      "epoch # 7 :\n",
      "\tTraining Accuracy:  0.2565707133917397\n",
      "\tTraining loss:  2.2001205800871646\n",
      "epoch # 8 :\n",
      "\tTraining Accuracy:  0.28660826032540676\n",
      "\tTraining loss:  2.175757430040597\n",
      "epoch # 9 :\n",
      "\tTraining Accuracy:  0.3078848560700876\n",
      "\tTraining loss:  2.1577531341614566\n",
      "epoch # 10 :\n",
      "\tTraining Accuracy:  0.3379224030037547\n",
      "\tTraining loss:  2.1425235839245262\n",
      "epoch # 11 :\n",
      "\tTraining Accuracy:  0.35294117647058826\n",
      "\tTraining loss:  2.120368012425635\n",
      "epoch # 12 :\n",
      "\tTraining Accuracy:  0.360450563204005\n",
      "\tTraining loss:  2.101777003000443\n",
      "epoch # 13 :\n",
      "\tTraining Accuracy:  0.37546933667083854\n",
      "\tTraining loss:  2.084956816813616\n",
      "epoch # 14 :\n",
      "\tTraining Accuracy:  0.4005006257822278\n",
      "\tTraining loss:  2.0599655468149662\n",
      "epoch # 15 :\n",
      "\tTraining Accuracy:  0.4230287859824781\n",
      "\tTraining loss:  2.0334096568079083\n",
      "epoch # 16 :\n",
      "\tTraining Accuracy:  0.4117647058823529\n",
      "\tTraining loss:  2.0134068523716797\n",
      "epoch # 17 :\n",
      "\tTraining Accuracy:  0.4380475594493116\n",
      "\tTraining loss:  1.9960721076343826\n",
      "epoch # 18 :\n",
      "\tTraining Accuracy:  0.43429286608260326\n",
      "\tTraining loss:  1.9758447051243364\n",
      "epoch # 19 :\n",
      "\tTraining Accuracy:  0.43679599499374216\n",
      "\tTraining loss:  1.959827118366159\n",
      "epoch # 20 :\n",
      "\tTraining Accuracy:  0.44430538172715894\n",
      "\tTraining loss:  1.9330047010553342\n",
      "epoch # 21 :\n",
      "\tTraining Accuracy:  0.4292866082603254\n",
      "\tTraining loss:  1.9117301330721352\n",
      "epoch # 22 :\n",
      "\tTraining Accuracy:  0.43178973717146435\n",
      "\tTraining loss:  1.8946474386828764\n",
      "epoch # 23 :\n",
      "\tTraining Accuracy:  0.44430538172715894\n",
      "\tTraining loss:  1.8731288047141275\n",
      "epoch # 24 :\n",
      "\tTraining Accuracy:  0.4693366708385482\n",
      "\tTraining loss:  1.8506833665900688\n",
      "epoch # 25 :\n",
      "\tTraining Accuracy:  0.4981226533166458\n",
      "\tTraining loss:  1.8314259672438837\n",
      "epoch # 26 :\n",
      "\tTraining Accuracy:  0.4793491864831039\n",
      "\tTraining loss:  1.815816084921286\n",
      "epoch # 27 :\n",
      "\tTraining Accuracy:  0.4856070087609512\n",
      "\tTraining loss:  1.7913109941866796\n",
      "epoch # 28 :\n",
      "\tTraining Accuracy:  0.49937421777221525\n",
      "\tTraining loss:  1.7687581275179303\n",
      "epoch # 29 :\n",
      "\tTraining Accuracy:  0.5244055068836045\n",
      "\tTraining loss:  1.748268795152836\n",
      "epoch # 30 :\n",
      "\tTraining Accuracy:  0.5469336670838548\n",
      "\tTraining loss:  1.7335341621311455\n",
      "epoch # 31 :\n",
      "\tTraining Accuracy:  0.5556946182728411\n",
      "\tTraining loss:  1.7126615794849231\n",
      "epoch # 32 :\n",
      "\tTraining Accuracy:  0.574468085106383\n",
      "\tTraining loss:  1.697529997632546\n",
      "epoch # 33 :\n",
      "\tTraining Accuracy:  0.5782227784730913\n",
      "\tTraining loss:  1.6774457638078404\n",
      "epoch # 34 :\n",
      "\tTraining Accuracy:  0.5894868585732165\n",
      "\tTraining loss:  1.661688815038297\n",
      "epoch # 35 :\n",
      "\tTraining Accuracy:  0.5944931163954944\n",
      "\tTraining loss:  1.6440198150508365\n",
      "epoch # 36 :\n",
      "\tTraining Accuracy:  0.6207759699624531\n",
      "\tTraining loss:  1.624387407525971\n",
      "epoch # 37 :\n",
      "\tTraining Accuracy:  0.6107634543178974\n",
      "\tTraining loss:  1.6037046877593415\n",
      "epoch # 38 :\n",
      "\tTraining Accuracy:  0.609511889862328\n",
      "\tTraining loss:  1.5860571367547236\n",
      "epoch # 39 :\n",
      "\tTraining Accuracy:  0.6057571964956195\n",
      "\tTraining loss:  1.5661913444384876\n",
      "epoch # 40 :\n",
      "\tTraining Accuracy:  0.6295369211514393\n",
      "\tTraining loss:  1.54306652493989\n",
      "epoch # 41 :\n",
      "\tTraining Accuracy:  0.6207759699624531\n",
      "\tTraining loss:  1.524576607361338\n",
      "epoch # 42 :\n",
      "\tTraining Accuracy:  0.6533166458072591\n",
      "\tTraining loss:  1.5090347757189846\n",
      "epoch # 43 :\n",
      "\tTraining Accuracy:  0.6458072590738423\n",
      "\tTraining loss:  1.49909412538418\n",
      "epoch # 44 :\n",
      "\tTraining Accuracy:  0.655819774718398\n",
      "\tTraining loss:  1.483681197462986\n",
      "epoch # 45 :\n",
      "\tTraining Accuracy:  0.6670838548185232\n",
      "\tTraining loss:  1.4675040403737762\n",
      "epoch # 46 :\n",
      "\tTraining Accuracy:  0.6583229036295369\n",
      "\tTraining loss:  1.4467327145162683\n",
      "epoch # 47 :\n",
      "\tTraining Accuracy:  0.6733416770963705\n",
      "\tTraining loss:  1.4272581845059018\n",
      "epoch # 48 :\n",
      "\tTraining Accuracy:  0.6783479349186483\n",
      "\tTraining loss:  1.4098621067373525\n",
      "epoch # 49 :\n",
      "\tTraining Accuracy:  0.6633291614518148\n",
      "\tTraining loss:  1.4000242353329944\n",
      "epoch # 50 :\n",
      "\tTraining Accuracy:  0.6846057571964956\n",
      "\tTraining loss:  1.3827820027600461\n",
      "epoch # 51 :\n",
      "\tTraining Accuracy:  0.6946182728410513\n",
      "\tTraining loss:  1.363982319192724\n",
      "epoch # 52 :\n",
      "\tTraining Accuracy:  0.7058823529411765\n",
      "\tTraining loss:  1.3505622310694365\n",
      "epoch # 53 :\n",
      "\tTraining Accuracy:  0.6933667083854819\n",
      "\tTraining loss:  1.3372982634264048\n",
      "epoch # 54 :\n",
      "\tTraining Accuracy:  0.7083854818523154\n",
      "\tTraining loss:  1.3319029525234376\n",
      "epoch # 55 :\n",
      "\tTraining Accuracy:  0.6971214017521903\n",
      "\tTraining loss:  1.3116676513249725\n",
      "epoch # 56 :\n",
      "\tTraining Accuracy:  0.7158948685857321\n",
      "\tTraining loss:  1.296392265003634\n",
      "epoch # 57 :\n",
      "\tTraining Accuracy:  0.723404255319149\n",
      "\tTraining loss:  1.280135676995622\n",
      "epoch # 58 :\n",
      "\tTraining Accuracy:  0.7196495619524406\n",
      "\tTraining loss:  1.262608713731301\n",
      "epoch # 59 :\n",
      "\tTraining Accuracy:  0.7246558197747184\n",
      "\tTraining loss:  1.2496891034832895\n",
      "epoch # 60 :\n",
      "\tTraining Accuracy:  0.753441802252816\n",
      "\tTraining loss:  1.237501622946598\n",
      "epoch # 61 :\n",
      "\tTraining Accuracy:  0.7309136420525657\n",
      "\tTraining loss:  1.2353118976543667\n",
      "epoch # 62 :\n",
      "\tTraining Accuracy:  0.7083854818523154\n",
      "\tTraining loss:  1.2234025794043362\n",
      "epoch # 63 :\n",
      "\tTraining Accuracy:  0.7271589486858573\n",
      "\tTraining loss:  1.2060450413991182\n",
      "epoch # 64 :\n",
      "\tTraining Accuracy:  0.7396745932415519\n",
      "\tTraining loss:  1.1864929263972839\n",
      "epoch # 65 :\n",
      "\tTraining Accuracy:  0.7459324155193993\n",
      "\tTraining loss:  1.1760642949792033\n",
      "epoch # 66 :\n",
      "\tTraining Accuracy:  0.7434292866082604\n",
      "\tTraining loss:  1.1650103754623533\n",
      "epoch # 67 :\n",
      "\tTraining Accuracy:  0.7484355444305382\n",
      "\tTraining loss:  1.152530134748551\n",
      "epoch # 68 :\n",
      "\tTraining Accuracy:  0.7484355444305382\n",
      "\tTraining loss:  1.1401926473393886\n",
      "epoch # 69 :\n",
      "\tTraining Accuracy:  0.7484355444305382\n",
      "\tTraining loss:  1.1306054660191105\n",
      "epoch # 70 :\n",
      "\tTraining Accuracy:  0.7596996245306633\n",
      "\tTraining loss:  1.114293634397891\n",
      "epoch # 71 :\n",
      "\tTraining Accuracy:  0.7484355444305382\n",
      "\tTraining loss:  1.1060504233037693\n",
      "epoch # 72 :\n",
      "\tTraining Accuracy:  0.7647058823529411\n",
      "\tTraining loss:  1.094337990347009\n",
      "epoch # 73 :\n",
      "\tTraining Accuracy:  0.7647058823529411\n",
      "\tTraining loss:  1.088267038977163\n",
      "epoch # 74 :\n",
      "\tTraining Accuracy:  0.7496871088861077\n",
      "\tTraining loss:  1.080643590688783\n",
      "epoch # 75 :\n",
      "\tTraining Accuracy:  0.7384230287859824\n",
      "\tTraining loss:  1.0780732227728966\n",
      "epoch # 76 :\n",
      "\tTraining Accuracy:  0.753441802252816\n",
      "\tTraining loss:  1.0684782414259784\n",
      "epoch # 77 :\n",
      "\tTraining Accuracy:  0.7596996245306633\n",
      "\tTraining loss:  1.051367709451537\n",
      "epoch # 78 :\n",
      "\tTraining Accuracy:  0.7471839799749687\n",
      "\tTraining loss:  1.044288560558615\n",
      "epoch # 79 :\n",
      "\tTraining Accuracy:  0.7434292866082604\n",
      "\tTraining loss:  1.0379370718436745\n",
      "epoch # 80 :\n",
      "\tTraining Accuracy:  0.7772215269086358\n",
      "\tTraining loss:  1.0262766041185207\n",
      "epoch # 81 :\n",
      "\tTraining Accuracy:  0.769712140175219\n",
      "\tTraining loss:  1.0169775538466184\n",
      "epoch # 82 :\n",
      "\tTraining Accuracy:  0.7772215269086358\n",
      "\tTraining loss:  1.008841157926587\n",
      "epoch # 83 :\n",
      "\tTraining Accuracy:  0.7784730913642053\n",
      "\tTraining loss:  0.9995467601665935\n",
      "epoch # 84 :\n",
      "\tTraining Accuracy:  0.769712140175219\n",
      "\tTraining loss:  0.997128786091164\n",
      "epoch # 85 :\n",
      "\tTraining Accuracy:  0.7584480600750939\n",
      "\tTraining loss:  0.9957161484193242\n",
      "epoch # 86 :\n",
      "\tTraining Accuracy:  0.7659574468085106\n",
      "\tTraining loss:  0.9846424691900677\n",
      "epoch # 87 :\n",
      "\tTraining Accuracy:  0.7772215269086358\n",
      "\tTraining loss:  0.9826555926469899\n",
      "epoch # 88 :\n",
      "\tTraining Accuracy:  0.7784730913642053\n",
      "\tTraining loss:  0.9697144760674807\n",
      "epoch # 89 :\n",
      "\tTraining Accuracy:  0.7847309136420526\n",
      "\tTraining loss:  0.9592578545161601\n",
      "epoch # 90 :\n",
      "\tTraining Accuracy:  0.7947434292866082\n",
      "\tTraining loss:  0.9504989537107504\n",
      "epoch # 91 :\n",
      "\tTraining Accuracy:  0.7809762202753442\n",
      "\tTraining loss:  0.945692113694707\n",
      "epoch # 92 :\n",
      "\tTraining Accuracy:  0.7734668335419274\n",
      "\tTraining loss:  0.94553501479714\n",
      "epoch # 93 :\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining Accuracy:  0.7959949937421777\n",
      "\tTraining loss:  0.93316627447876\n",
      "epoch # 94 :\n",
      "\tTraining Accuracy:  0.7972465581977471\n",
      "\tTraining loss:  0.9289603082300973\n",
      "epoch # 95 :\n",
      "\tTraining Accuracy:  0.7784730913642053\n",
      "\tTraining loss:  0.9353002656431489\n",
      "epoch # 96 :\n",
      "\tTraining Accuracy:  0.7922403003754693\n",
      "\tTraining loss:  0.92586339226834\n",
      "epoch # 97 :\n",
      "\tTraining Accuracy:  0.785982478097622\n",
      "\tTraining loss:  0.9158832675687648\n",
      "epoch # 98 :\n",
      "\tTraining Accuracy:  0.8022528160200251\n",
      "\tTraining loss:  0.9051699423512224\n",
      "epoch # 99 :\n",
      "\tTraining Accuracy:  0.7947434292866082\n",
      "\tTraining loss:  0.910307301409399\n"
     ]
    }
   ],
   "source": [
    "model.train(Ytr, Xtr, Xva, Yva, epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model = tf.keras.models.Sequential()\n",
    "\n",
    "def create_dense(n):\n",
    "    return tf.keras.layers.Dense(n,\n",
    "                use_bias = False)\n",
    "#                 activation='relu',\n",
    "#                 kernel_initializer=tf.ones_initializer())\n",
    "#               kernel_initializer=tf.random_uniform_initializer(minval=-1, maxval=1))\n",
    "\n",
    "tf_model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "tf_model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "# tf_model.add(tf.keras.layers.Softmax())\n",
    "\n",
    "tf_model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.01),\n",
    "                 loss = tf.keras.losses.categorical_crossentropy,\n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "799/799 [==============================] - 2s 3ms/step - loss: 2.2991 - acc: 0.1777\n",
      "Epoch 2/100\n",
      "799/799 [==============================] - 0s 150us/step - loss: 2.1632 - acc: 0.2941\n",
      "Epoch 3/100\n",
      "799/799 [==============================] - 0s 149us/step - loss: 2.0451 - acc: 0.3930\n",
      "Epoch 4/100\n",
      "799/799 [==============================] - 0s 144us/step - loss: 1.9321 - acc: 0.4568\n",
      "Epoch 5/100\n",
      "799/799 [==============================] - 0s 146us/step - loss: 1.8218 - acc: 0.5257\n",
      "Epoch 6/100\n",
      "799/799 [==============================] - 0s 145us/step - loss: 1.7183 - acc: 0.5732\n",
      "Epoch 7/100\n",
      "799/799 [==============================] - 0s 147us/step - loss: 1.6171 - acc: 0.6108\n",
      "Epoch 8/100\n",
      "799/799 [==============================] - 0s 142us/step - loss: 1.5237 - acc: 0.6608\n",
      "Epoch 9/100\n",
      "799/799 [==============================] - 0s 142us/step - loss: 1.4349 - acc: 0.6859\n",
      "Epoch 10/100\n",
      "799/799 [==============================] - 0s 130us/step - loss: 1.3505 - acc: 0.7096\n",
      "Epoch 11/100\n",
      "799/799 [==============================] - 0s 136us/step - loss: 1.2711 - acc: 0.7334\n",
      "Epoch 12/100\n",
      "799/799 [==============================] - 0s 134us/step - loss: 1.1977 - acc: 0.7559\n",
      "Epoch 13/100\n",
      "799/799 [==============================] - 0s 135us/step - loss: 1.1301 - acc: 0.7610\n",
      "Epoch 14/100\n",
      "799/799 [==============================] - 0s 130us/step - loss: 1.0682 - acc: 0.7760\n",
      "Epoch 15/100\n",
      "799/799 [==============================] - 0s 135us/step - loss: 1.0124 - acc: 0.7897\n",
      "Epoch 16/100\n",
      "799/799 [==============================] - 0s 140us/step - loss: 0.9608 - acc: 0.7947\n",
      "Epoch 17/100\n",
      "799/799 [==============================] - 0s 146us/step - loss: 0.9143 - acc: 0.8010\n",
      "Epoch 18/100\n",
      "799/799 [==============================] - 0s 140us/step - loss: 0.8723 - acc: 0.8110\n",
      "Epoch 19/100\n",
      "799/799 [==============================] - 0s 141us/step - loss: 0.8348 - acc: 0.8198\n",
      "Epoch 20/100\n",
      "799/799 [==============================] - 0s 146us/step - loss: 0.7996 - acc: 0.8260\n",
      "Epoch 21/100\n",
      "799/799 [==============================] - 0s 142us/step - loss: 0.7673 - acc: 0.8360\n",
      "Epoch 22/100\n",
      "799/799 [==============================] - 0s 143us/step - loss: 0.7389 - acc: 0.8436\n",
      "Epoch 23/100\n",
      "799/799 [==============================] - 0s 146us/step - loss: 0.7128 - acc: 0.8448\n",
      "Epoch 24/100\n",
      "799/799 [==============================] - 0s 149us/step - loss: 0.6894 - acc: 0.8473\n",
      "Epoch 25/100\n",
      "799/799 [==============================] - 0s 141us/step - loss: 0.6677 - acc: 0.8548\n",
      "Epoch 26/100\n",
      "799/799 [==============================] - 0s 150us/step - loss: 0.6479 - acc: 0.8598\n",
      "Epoch 27/100\n",
      "799/799 [==============================] - 0s 154us/step - loss: 0.6281 - acc: 0.8598\n",
      "Epoch 28/100\n",
      "799/799 [==============================] - 0s 156us/step - loss: 0.6100 - acc: 0.8611\n",
      "Epoch 29/100\n",
      "799/799 [==============================] - 0s 158us/step - loss: 0.5943 - acc: 0.8698\n",
      "Epoch 30/100\n",
      "799/799 [==============================] - 0s 154us/step - loss: 0.5788 - acc: 0.8698\n",
      "Epoch 31/100\n",
      "799/799 [==============================] - 0s 149us/step - loss: 0.5640 - acc: 0.8761\n",
      "Epoch 32/100\n",
      "799/799 [==============================] - 0s 154us/step - loss: 0.5501 - acc: 0.8786\n",
      "Epoch 33/100\n",
      "799/799 [==============================] - 0s 158us/step - loss: 0.5373 - acc: 0.8836\n",
      "Epoch 34/100\n",
      "799/799 [==============================] - 0s 143us/step - loss: 0.5255 - acc: 0.8874\n",
      "Epoch 35/100\n",
      "799/799 [==============================] - 0s 151us/step - loss: 0.5142 - acc: 0.8836\n",
      "Epoch 36/100\n",
      "799/799 [==============================] - 0s 155us/step - loss: 0.5015 - acc: 0.8886\n",
      "Epoch 37/100\n",
      "799/799 [==============================] - 0s 159us/step - loss: 0.4925 - acc: 0.8924\n",
      "Epoch 38/100\n",
      "799/799 [==============================] - 0s 146us/step - loss: 0.4823 - acc: 0.8911\n",
      "Epoch 39/100\n",
      "799/799 [==============================] - 0s 140us/step - loss: 0.4732 - acc: 0.8961\n",
      "Epoch 40/100\n",
      "799/799 [==============================] - 0s 149us/step - loss: 0.4633 - acc: 0.8974\n",
      "Epoch 41/100\n",
      "799/799 [==============================] - 0s 146us/step - loss: 0.4542 - acc: 0.8986\n",
      "Epoch 42/100\n",
      "799/799 [==============================] - 0s 148us/step - loss: 0.4460 - acc: 0.9036\n",
      "Epoch 43/100\n",
      "799/799 [==============================] - 0s 150us/step - loss: 0.4377 - acc: 0.9111\n",
      "Epoch 44/100\n",
      "799/799 [==============================] - 0s 146us/step - loss: 0.4299 - acc: 0.9049\n",
      "Epoch 45/100\n",
      "799/799 [==============================] - 0s 149us/step - loss: 0.4222 - acc: 0.9099\n",
      "Epoch 46/100\n",
      "799/799 [==============================] - 0s 161us/step - loss: 0.4163 - acc: 0.9124\n",
      "Epoch 47/100\n",
      "799/799 [==============================] - 0s 155us/step - loss: 0.4096 - acc: 0.9174\n",
      "Epoch 48/100\n",
      "799/799 [==============================] - 0s 140us/step - loss: 0.4019 - acc: 0.9149\n",
      "Epoch 49/100\n",
      "799/799 [==============================] - 0s 145us/step - loss: 0.3956 - acc: 0.9212\n",
      "Epoch 50/100\n",
      "799/799 [==============================] - 0s 150us/step - loss: 0.3896 - acc: 0.9224\n",
      "Epoch 51/100\n",
      "799/799 [==============================] - 0s 142us/step - loss: 0.3831 - acc: 0.9237\n",
      "Epoch 52/100\n",
      "799/799 [==============================] - 0s 151us/step - loss: 0.3779 - acc: 0.9249\n",
      "Epoch 53/100\n",
      "799/799 [==============================] - 0s 145us/step - loss: 0.3721 - acc: 0.9287\n",
      "Epoch 54/100\n",
      "799/799 [==============================] - 0s 150us/step - loss: 0.3665 - acc: 0.9249\n",
      "Epoch 55/100\n",
      "799/799 [==============================] - 0s 151us/step - loss: 0.3617 - acc: 0.9249\n",
      "Epoch 56/100\n",
      "799/799 [==============================] - 0s 144us/step - loss: 0.3565 - acc: 0.9262\n",
      "Epoch 57/100\n",
      "799/799 [==============================] - 0s 130us/step - loss: 0.3512 - acc: 0.9312\n",
      "Epoch 58/100\n",
      "799/799 [==============================] - 0s 145us/step - loss: 0.3466 - acc: 0.9274\n",
      "Epoch 59/100\n",
      "799/799 [==============================] - 0s 145us/step - loss: 0.3423 - acc: 0.9299\n",
      "Epoch 60/100\n",
      "799/799 [==============================] - 0s 145us/step - loss: 0.3373 - acc: 0.9287\n",
      "Epoch 61/100\n",
      "799/799 [==============================] - 0s 143us/step - loss: 0.3333 - acc: 0.9324\n",
      "Epoch 62/100\n",
      "799/799 [==============================] - 0s 145us/step - loss: 0.3288 - acc: 0.9274\n",
      "Epoch 63/100\n",
      "799/799 [==============================] - 0s 144us/step - loss: 0.3242 - acc: 0.9362\n",
      "Epoch 64/100\n",
      "799/799 [==============================] - 0s 144us/step - loss: 0.3202 - acc: 0.9349\n",
      "Epoch 65/100\n",
      "799/799 [==============================] - 0s 149us/step - loss: 0.3152 - acc: 0.9349\n",
      "Epoch 66/100\n",
      "799/799 [==============================] - 0s 147us/step - loss: 0.3119 - acc: 0.9374\n",
      "Epoch 67/100\n",
      "799/799 [==============================] - 0s 143us/step - loss: 0.3085 - acc: 0.9349\n",
      "Epoch 68/100\n",
      "799/799 [==============================] - 0s 136us/step - loss: 0.3052 - acc: 0.9387\n",
      "Epoch 69/100\n",
      "799/799 [==============================] - 0s 142us/step - loss: 0.3008 - acc: 0.9387\n",
      "Epoch 70/100\n",
      "799/799 [==============================] - 0s 145us/step - loss: 0.2976 - acc: 0.9412\n",
      "Epoch 71/100\n",
      "799/799 [==============================] - 0s 145us/step - loss: 0.2943 - acc: 0.9412\n",
      "Epoch 72/100\n",
      "799/799 [==============================] - 0s 150us/step - loss: 0.2908 - acc: 0.9412\n",
      "Epoch 73/100\n",
      "799/799 [==============================] - 0s 140us/step - loss: 0.2870 - acc: 0.9424\n",
      "Epoch 74/100\n",
      "799/799 [==============================] - 0s 132us/step - loss: 0.2833 - acc: 0.9449\n",
      "Epoch 75/100\n",
      "799/799 [==============================] - 0s 144us/step - loss: 0.2808 - acc: 0.9424\n",
      "Epoch 76/100\n",
      "799/799 [==============================] - 0s 141us/step - loss: 0.2770 - acc: 0.9412\n",
      "Epoch 77/100\n",
      "799/799 [==============================] - 0s 146us/step - loss: 0.2735 - acc: 0.9499\n",
      "Epoch 78/100\n",
      "799/799 [==============================] - 0s 148us/step - loss: 0.2711 - acc: 0.9474\n",
      "Epoch 79/100\n",
      "799/799 [==============================] - 0s 138us/step - loss: 0.2681 - acc: 0.9449\n",
      "Epoch 80/100\n",
      "799/799 [==============================] - 0s 151us/step - loss: 0.2652 - acc: 0.9487\n",
      "Epoch 81/100\n",
      "799/799 [==============================] - 0s 148us/step - loss: 0.2618 - acc: 0.9449\n",
      "Epoch 82/100\n",
      "799/799 [==============================] - 0s 136us/step - loss: 0.2591 - acc: 0.9487\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "799/799 [==============================] - 0s 129us/step - loss: 0.2567 - acc: 0.9499\n",
      "Epoch 84/100\n",
      "799/799 [==============================] - 0s 135us/step - loss: 0.2530 - acc: 0.9499\n",
      "Epoch 85/100\n",
      "799/799 [==============================] - 0s 134us/step - loss: 0.2512 - acc: 0.9512\n",
      "Epoch 86/100\n",
      "799/799 [==============================] - 0s 127us/step - loss: 0.2480 - acc: 0.9512\n",
      "Epoch 87/100\n",
      "799/799 [==============================] - 0s 132us/step - loss: 0.2456 - acc: 0.9487\n",
      "Epoch 88/100\n",
      "799/799 [==============================] - 0s 142us/step - loss: 0.2437 - acc: 0.9549\n",
      "Epoch 89/100\n",
      "799/799 [==============================] - 0s 146us/step - loss: 0.2408 - acc: 0.9537\n",
      "Epoch 90/100\n",
      "799/799 [==============================] - 0s 146us/step - loss: 0.2376 - acc: 0.9574\n",
      "Epoch 91/100\n",
      "799/799 [==============================] - 0s 144us/step - loss: 0.2360 - acc: 0.9524\n",
      "Epoch 92/100\n",
      "799/799 [==============================] - 0s 140us/step - loss: 0.2331 - acc: 0.9587\n",
      "Epoch 93/100\n",
      "799/799 [==============================] - 0s 150us/step - loss: 0.2307 - acc: 0.9562\n",
      "Epoch 94/100\n",
      "799/799 [==============================] - 0s 141us/step - loss: 0.2287 - acc: 0.9587\n",
      "Epoch 95/100\n",
      "799/799 [==============================] - 0s 136us/step - loss: 0.2260 - acc: 0.9599\n",
      "Epoch 96/100\n",
      "799/799 [==============================] - 0s 136us/step - loss: 0.2240 - acc: 0.9612\n",
      "Epoch 97/100\n",
      "799/799 [==============================] - 0s 141us/step - loss: 0.2215 - acc: 0.9612\n",
      "Epoch 98/100\n",
      "799/799 [==============================] - 0s 142us/step - loss: 0.2187 - acc: 0.9625\n",
      "Epoch 99/100\n",
      "799/799 [==============================] - 0s 145us/step - loss: 0.2171 - acc: 0.9587\n",
      "Epoch 100/100\n",
      "799/799 [==============================] - 0s 140us/step - loss: 0.2150 - acc: 0.9637\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x1b5bc2ecba8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_model.fit(Xtr, Ytr, epochs = 100, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
