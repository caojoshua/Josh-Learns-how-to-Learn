{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "    import imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import NeuralNetwork as nn\n",
    "import numpy as np\n",
    "from sklearn import *\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caojo\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\caojo\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\caojo\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\caojo\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\caojo\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\caojo\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(999, 785)\n"
     ]
    }
   ],
   "source": [
    "data = np.genfromtxt(\"data/train_small.csv\", delimiter=\",\", skip_header=1, dtype=float)\n",
    "# data = data[:50]\n",
    "# data = np.genfromtxt(\"data/generated_dataset.csv\", delimiter=\",\", skip_header=1, dtype=float)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(999, 784)\n",
      "(999,)\n"
     ]
    }
   ],
   "source": [
    "X = data[:,1:]\n",
    "Y = data[:,0]\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(999, 784)\n"
     ]
    }
   ],
   "source": [
    "X /= np.max(X)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(999, 10)\n"
     ]
    }
   ],
   "source": [
    "Y = Y.astype(dtype=int)\n",
    "tempY = np.zeros(shape=(len(Y), np.max(Y)+1))\n",
    "tempY[np.arange(len(Y)),Y] = 1\n",
    "Y = tempY\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train/validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(799, 784)\n",
      "(799, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caojo\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "Xtr, Xva, Ytr, Yva = model_selection.train_test_split(X, Y, train_size=.80, random_state=0)\n",
    "\n",
    "print(Xtr.shape)\n",
    "print(Ytr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.NeuralNetwork(input_length = Xtr.shape[1], lr=0.01, loss=nn.LossFunction.CrossEntropy())\n",
    "model.add_layer(nn.Layer.FullyConnectedLayer, num_neurons = 32)\n",
    "model.add_layer(nn.Layer.Relu)\n",
    "model.add_layer(nn.Layer.FullyConnectedLayer, num_neurons = 10)\n",
    "model.add_layer(nn.Layer.Softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch # 0 :\n",
      "\tTraining Accuracy:  0.11389236545682102\n",
      "\tValidation Accuracy:  0.085\n",
      "\tTraining loss:  2.299397771084507\n",
      "\tvalidation loss:  2.345184038780209\n",
      "epoch # 1 :\n",
      "\tTraining Accuracy:  0.13016270337922403\n",
      "\tValidation Accuracy:  0.1\n",
      "\tTraining loss:  2.2697432300763287\n",
      "\tvalidation loss:  2.3092005896007897\n",
      "epoch # 2 :\n",
      "\tTraining Accuracy:  0.13892365456821026\n",
      "\tValidation Accuracy:  0.095\n",
      "\tTraining loss:  2.245404497029948\n",
      "\tvalidation loss:  2.284409036890366\n",
      "epoch # 3 :\n",
      "\tTraining Accuracy:  0.16645807259073842\n",
      "\tValidation Accuracy:  0.12\n",
      "\tTraining loss:  2.222116003696036\n",
      "\tvalidation loss:  2.2618519650979976\n",
      "epoch # 4 :\n",
      "\tTraining Accuracy:  0.19148936170212766\n",
      "\tValidation Accuracy:  0.155\n",
      "\tTraining loss:  2.200567114475977\n",
      "\tvalidation loss:  2.2420032966630643\n",
      "epoch # 5 :\n",
      "\tTraining Accuracy:  0.2165206508135169\n",
      "\tValidation Accuracy:  0.19\n",
      "\tTraining loss:  2.1746152585048657\n",
      "\tvalidation loss:  2.2114749268038465\n",
      "epoch # 6 :\n",
      "\tTraining Accuracy:  0.23529411764705882\n",
      "\tValidation Accuracy:  0.19\n",
      "\tTraining loss:  2.1591787689695012\n",
      "\tvalidation loss:  2.196029743179309\n",
      "epoch # 7 :\n",
      "\tTraining Accuracy:  0.25156445556946183\n",
      "\tValidation Accuracy:  0.195\n",
      "\tTraining loss:  2.139036414408523\n",
      "\tvalidation loss:  2.1779002499232316\n",
      "epoch # 8 :\n",
      "\tTraining Accuracy:  0.2765957446808511\n",
      "\tValidation Accuracy:  0.23\n",
      "\tTraining loss:  2.1132705469418784\n",
      "\tvalidation loss:  2.1541420438236596\n",
      "epoch # 9 :\n",
      "\tTraining Accuracy:  0.2753441802252816\n",
      "\tValidation Accuracy:  0.25\n",
      "\tTraining loss:  2.0965169549793603\n",
      "\tvalidation loss:  2.1395438010566865\n",
      "epoch # 10 :\n",
      "\tTraining Accuracy:  0.28660826032540676\n",
      "\tValidation Accuracy:  0.275\n",
      "\tTraining loss:  2.076932442845058\n",
      "\tvalidation loss:  2.1153381245063727\n",
      "epoch # 11 :\n",
      "\tTraining Accuracy:  0.3304130162703379\n",
      "\tValidation Accuracy:  0.295\n",
      "\tTraining loss:  2.051175319906644\n",
      "\tvalidation loss:  2.0887190810717984\n",
      "epoch # 12 :\n",
      "\tTraining Accuracy:  0.3304130162703379\n",
      "\tValidation Accuracy:  0.305\n",
      "\tTraining loss:  2.0367690654648216\n",
      "\tvalidation loss:  2.081228774674074\n",
      "epoch # 13 :\n",
      "\tTraining Accuracy:  0.3091364205256571\n",
      "\tValidation Accuracy:  0.275\n",
      "\tTraining loss:  2.021197098735615\n",
      "\tvalidation loss:  2.0779774156337094\n",
      "epoch # 14 :\n",
      "\tTraining Accuracy:  0.35168961201501875\n",
      "\tValidation Accuracy:  0.305\n",
      "\tTraining loss:  1.9965165467094548\n",
      "\tvalidation loss:  2.0483410028699245\n",
      "epoch # 15 :\n",
      "\tTraining Accuracy:  0.37797246558197745\n",
      "\tValidation Accuracy:  0.355\n",
      "\tTraining loss:  1.9703309525979624\n",
      "\tvalidation loss:  2.0116335516218484\n",
      "epoch # 16 :\n",
      "\tTraining Accuracy:  0.38923654568210264\n",
      "\tValidation Accuracy:  0.36\n",
      "\tTraining loss:  1.9491481313846886\n",
      "\tvalidation loss:  1.9894300995601855\n",
      "epoch # 17 :\n",
      "\tTraining Accuracy:  0.38172715894868586\n",
      "\tValidation Accuracy:  0.355\n",
      "\tTraining loss:  1.9324835252581558\n",
      "\tvalidation loss:  1.970746704955714\n",
      "epoch # 18 :\n",
      "\tTraining Accuracy:  0.41551939924906134\n",
      "\tValidation Accuracy:  0.41\n",
      "\tTraining loss:  1.9089410806671974\n",
      "\tvalidation loss:  1.9392838835581185\n",
      "epoch # 19 :\n",
      "\tTraining Accuracy:  0.45056320400500627\n",
      "\tValidation Accuracy:  0.44\n",
      "\tTraining loss:  1.8812816718630185\n",
      "\tvalidation loss:  1.897334642038499\n",
      "epoch # 20 :\n",
      "\tTraining Accuracy:  0.4643304130162703\n",
      "\tValidation Accuracy:  0.46\n",
      "\tTraining loss:  1.8617950850271814\n",
      "\tvalidation loss:  1.875782200765592\n",
      "epoch # 21 :\n",
      "\tTraining Accuracy:  0.48936170212765956\n",
      "\tValidation Accuracy:  0.5\n",
      "\tTraining loss:  1.8396127676950584\n",
      "\tvalidation loss:  1.8541182784012635\n",
      "epoch # 22 :\n",
      "\tTraining Accuracy:  0.4981226533166458\n",
      "\tValidation Accuracy:  0.515\n",
      "\tTraining loss:  1.8184180925469433\n",
      "\tvalidation loss:  1.8256169289146333\n",
      "epoch # 23 :\n",
      "\tTraining Accuracy:  0.5068836045056321\n",
      "\tValidation Accuracy:  0.5\n",
      "\tTraining loss:  1.7978322004345522\n",
      "\tvalidation loss:  1.810349989165049\n",
      "epoch # 24 :\n",
      "\tTraining Accuracy:  0.509386733416771\n",
      "\tValidation Accuracy:  0.535\n",
      "\tTraining loss:  1.7781184003950028\n",
      "\tvalidation loss:  1.7918951065095738\n",
      "epoch # 25 :\n",
      "\tTraining Accuracy:  0.5306633291614519\n",
      "\tValidation Accuracy:  0.51\n",
      "\tTraining loss:  1.75539879567131\n",
      "\tvalidation loss:  1.7728504576941984\n",
      "epoch # 26 :\n",
      "\tTraining Accuracy:  0.5481852315394243\n",
      "\tValidation Accuracy:  0.56\n",
      "\tTraining loss:  1.7317914824238434\n",
      "\tvalidation loss:  1.7506664457031917\n",
      "epoch # 27 :\n",
      "\tTraining Accuracy:  0.5531914893617021\n",
      "\tValidation Accuracy:  0.55\n",
      "\tTraining loss:  1.7123872542090979\n",
      "\tvalidation loss:  1.7355677801542664\n",
      "epoch # 28 :\n",
      "\tTraining Accuracy:  0.55819774718398\n",
      "\tValidation Accuracy:  0.54\n",
      "\tTraining loss:  1.6935041615523299\n",
      "\tvalidation loss:  1.719038978786946\n",
      "epoch # 29 :\n",
      "\tTraining Accuracy:  0.5632040050062578\n",
      "\tValidation Accuracy:  0.55\n",
      "\tTraining loss:  1.6709772685795483\n",
      "\tvalidation loss:  1.692046322957511\n",
      "epoch # 30 :\n",
      "\tTraining Accuracy:  0.5757196495619524\n",
      "\tValidation Accuracy:  0.575\n",
      "\tTraining loss:  1.651549426111748\n",
      "\tvalidation loss:  1.6702174855000573\n",
      "epoch # 31 :\n",
      "\tTraining Accuracy:  0.5794743429286608\n",
      "\tValidation Accuracy:  0.575\n",
      "\tTraining loss:  1.6318631257625626\n",
      "\tvalidation loss:  1.6462783156323746\n",
      "epoch # 32 :\n",
      "\tTraining Accuracy:  0.5732165206508135\n",
      "\tValidation Accuracy:  0.57\n",
      "\tTraining loss:  1.6132168369045663\n",
      "\tvalidation loss:  1.6239830242120434\n",
      "epoch # 33 :\n",
      "\tTraining Accuracy:  0.5894868585732165\n",
      "\tValidation Accuracy:  0.58\n",
      "\tTraining loss:  1.5961048315044486\n",
      "\tvalidation loss:  1.6072837613073077\n",
      "epoch # 34 :\n",
      "\tTraining Accuracy:  0.6057571964956195\n",
      "\tValidation Accuracy:  0.59\n",
      "\tTraining loss:  1.5773377138864224\n",
      "\tvalidation loss:  1.5904092410323847\n",
      "epoch # 35 :\n",
      "\tTraining Accuracy:  0.6020025031289111\n",
      "\tValidation Accuracy:  0.59\n",
      "\tTraining loss:  1.559769838963678\n",
      "\tvalidation loss:  1.5702217382794186\n",
      "epoch # 36 :\n",
      "\tTraining Accuracy:  0.6282853566958698\n",
      "\tValidation Accuracy:  0.605\n",
      "\tTraining loss:  1.5408729222349453\n",
      "\tvalidation loss:  1.5503130327413988\n",
      "epoch # 37 :\n",
      "\tTraining Accuracy:  0.6257822277847309\n",
      "\tValidation Accuracy:  0.615\n",
      "\tTraining loss:  1.5243160350054903\n",
      "\tvalidation loss:  1.5308092878162471\n",
      "epoch # 38 :\n",
      "\tTraining Accuracy:  0.6170212765957447\n",
      "\tValidation Accuracy:  0.615\n",
      "\tTraining loss:  1.504607444847828\n",
      "\tvalidation loss:  1.5129506167284288\n",
      "epoch # 39 :\n",
      "\tTraining Accuracy:  0.6257822277847309\n",
      "\tValidation Accuracy:  0.605\n",
      "\tTraining loss:  1.4875264768468088\n",
      "\tvalidation loss:  1.4910859080881997\n",
      "epoch # 40 :\n",
      "\tTraining Accuracy:  0.6307884856070087\n",
      "\tValidation Accuracy:  0.625\n",
      "\tTraining loss:  1.4708263694949906\n",
      "\tvalidation loss:  1.473552056339577\n",
      "epoch # 41 :\n",
      "\tTraining Accuracy:  0.6508135168961201\n",
      "\tValidation Accuracy:  0.63\n",
      "\tTraining loss:  1.45693089283899\n",
      "\tvalidation loss:  1.4567602023417876\n",
      "epoch # 42 :\n",
      "\tTraining Accuracy:  0.6495619524405507\n",
      "\tValidation Accuracy:  0.625\n",
      "\tTraining loss:  1.4496507799476461\n",
      "\tvalidation loss:  1.4499999623816735\n",
      "epoch # 43 :\n",
      "\tTraining Accuracy:  0.6382978723404256\n",
      "\tValidation Accuracy:  0.64\n",
      "\tTraining loss:  1.4377095639948108\n",
      "\tvalidation loss:  1.4298244691410396\n",
      "epoch # 44 :\n",
      "\tTraining Accuracy:  0.6733416770963705\n",
      "\tValidation Accuracy:  0.665\n",
      "\tTraining loss:  1.4150943864557242\n",
      "\tvalidation loss:  1.4257169362183368\n",
      "epoch # 45 :\n",
      "\tTraining Accuracy:  0.6595744680851063\n",
      "\tValidation Accuracy:  0.645\n",
      "\tTraining loss:  1.3988145792577025\n",
      "\tvalidation loss:  1.4123768475208018\n",
      "epoch # 46 :\n",
      "\tTraining Accuracy:  0.672090112640801\n",
      "\tValidation Accuracy:  0.665\n",
      "\tTraining loss:  1.3830653571642317\n",
      "\tvalidation loss:  1.385954198375466\n",
      "epoch # 47 :\n",
      "\tTraining Accuracy:  0.6708385481852316\n",
      "\tValidation Accuracy:  0.66\n",
      "\tTraining loss:  1.3653210315094548\n",
      "\tvalidation loss:  1.3725688388207096\n",
      "epoch # 48 :\n",
      "\tTraining Accuracy:  0.6770963704630788\n",
      "\tValidation Accuracy:  0.675\n",
      "\tTraining loss:  1.353339021893254\n",
      "\tvalidation loss:  1.3630157211605234\n",
      "epoch # 49 :\n",
      "\tTraining Accuracy:  0.6795994993742178\n",
      "\tValidation Accuracy:  0.685\n",
      "\tTraining loss:  1.3430666750057136\n",
      "\tvalidation loss:  1.3503499335823648\n",
      "epoch # 50 :\n",
      "\tTraining Accuracy:  0.6871088861076345\n",
      "\tValidation Accuracy:  0.685\n",
      "\tTraining loss:  1.3268052138972066\n",
      "\tvalidation loss:  1.3411316417087766\n",
      "epoch # 51 :\n",
      "\tTraining Accuracy:  0.7021276595744681\n",
      "\tValidation Accuracy:  0.685\n",
      "\tTraining loss:  1.3074617018562136\n",
      "\tvalidation loss:  1.3151547460009567\n",
      "epoch # 52 :\n",
      "\tTraining Accuracy:  0.7196495619524406\n",
      "\tValidation Accuracy:  0.69\n",
      "\tTraining loss:  1.2942005461344073\n",
      "\tvalidation loss:  1.2941216137251357\n",
      "epoch # 53 :\n",
      "\tTraining Accuracy:  0.723404255319149\n",
      "\tValidation Accuracy:  0.705\n",
      "\tTraining loss:  1.2849875906475803\n",
      "\tvalidation loss:  1.2833620247381772\n",
      "epoch # 54 :\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining Accuracy:  0.7146433041301627\n",
      "\tValidation Accuracy:  0.695\n",
      "\tTraining loss:  1.268614768000721\n",
      "\tvalidation loss:  1.2675971977354237\n",
      "epoch # 55 :\n",
      "\tTraining Accuracy:  0.7121401752190237\n",
      "\tValidation Accuracy:  0.68\n",
      "\tTraining loss:  1.2582781874666653\n",
      "\tvalidation loss:  1.2680123811916033\n",
      "epoch # 56 :\n",
      "\tTraining Accuracy:  0.7246558197747184\n",
      "\tValidation Accuracy:  0.67\n",
      "\tTraining loss:  1.2435092723470924\n",
      "\tvalidation loss:  1.2522862422552934\n",
      "epoch # 57 :\n",
      "\tTraining Accuracy:  0.7058823529411765\n",
      "\tValidation Accuracy:  0.69\n",
      "\tTraining loss:  1.2319228120591574\n",
      "\tvalidation loss:  1.2297770824047252\n",
      "epoch # 58 :\n",
      "\tTraining Accuracy:  0.723404255319149\n",
      "\tValidation Accuracy:  0.725\n",
      "\tTraining loss:  1.2187344449993005\n",
      "\tvalidation loss:  1.2104508469095714\n",
      "epoch # 59 :\n",
      "\tTraining Accuracy:  0.7346683354192741\n",
      "\tValidation Accuracy:  0.7\n",
      "\tTraining loss:  1.208444370857432\n",
      "\tvalidation loss:  1.2002674638992448\n",
      "epoch # 60 :\n",
      "\tTraining Accuracy:  0.7296620775969962\n",
      "\tValidation Accuracy:  0.715\n",
      "\tTraining loss:  1.1984443717738262\n",
      "\tvalidation loss:  1.1913883556092433\n",
      "epoch # 61 :\n",
      "\tTraining Accuracy:  0.7296620775969962\n",
      "\tValidation Accuracy:  0.73\n",
      "\tTraining loss:  1.1886138440195582\n",
      "\tvalidation loss:  1.1820820315783578\n",
      "epoch # 62 :\n",
      "\tTraining Accuracy:  0.7471839799749687\n",
      "\tValidation Accuracy:  0.73\n",
      "\tTraining loss:  1.1739192107617962\n",
      "\tvalidation loss:  1.1746212984104982\n",
      "epoch # 63 :\n",
      "\tTraining Accuracy:  0.7434292866082604\n",
      "\tValidation Accuracy:  0.74\n",
      "\tTraining loss:  1.161588389562302\n",
      "\tvalidation loss:  1.155732180078304\n",
      "epoch # 64 :\n",
      "\tTraining Accuracy:  0.7446808510638298\n",
      "\tValidation Accuracy:  0.73\n",
      "\tTraining loss:  1.150442317529664\n",
      "\tvalidation loss:  1.1439629978311003\n",
      "epoch # 65 :\n",
      "\tTraining Accuracy:  0.7484355444305382\n",
      "\tValidation Accuracy:  0.725\n",
      "\tTraining loss:  1.1400471569621429\n",
      "\tvalidation loss:  1.1326797359936949\n",
      "epoch # 66 :\n",
      "\tTraining Accuracy:  0.7559449311639549\n",
      "\tValidation Accuracy:  0.75\n",
      "\tTraining loss:  1.1263679335240917\n",
      "\tvalidation loss:  1.1261333151989177\n",
      "epoch # 67 :\n",
      "\tTraining Accuracy:  0.7622027534418022\n",
      "\tValidation Accuracy:  0.74\n",
      "\tTraining loss:  1.1186682630535243\n",
      "\tvalidation loss:  1.1223273957661364\n",
      "epoch # 68 :\n",
      "\tTraining Accuracy:  0.7634543178973717\n",
      "\tValidation Accuracy:  0.75\n",
      "\tTraining loss:  1.1121178030478516\n",
      "\tvalidation loss:  1.1169499584809686\n",
      "epoch # 69 :\n",
      "\tTraining Accuracy:  0.7659574468085106\n",
      "\tValidation Accuracy:  0.745\n",
      "\tTraining loss:  1.0998970729045991\n",
      "\tvalidation loss:  1.0990270744000636\n",
      "epoch # 70 :\n",
      "\tTraining Accuracy:  0.7622027534418022\n",
      "\tValidation Accuracy:  0.75\n",
      "\tTraining loss:  1.088334660742845\n",
      "\tvalidation loss:  1.0911251320964537\n",
      "epoch # 71 :\n",
      "\tTraining Accuracy:  0.7672090112640801\n",
      "\tValidation Accuracy:  0.735\n",
      "\tTraining loss:  1.0785201531851263\n",
      "\tvalidation loss:  1.072458548130344\n",
      "epoch # 72 :\n",
      "\tTraining Accuracy:  0.7559449311639549\n",
      "\tValidation Accuracy:  0.73\n",
      "\tTraining loss:  1.072825857736086\n",
      "\tvalidation loss:  1.0674967865369627\n",
      "epoch # 73 :\n",
      "\tTraining Accuracy:  0.7546933667083855\n",
      "\tValidation Accuracy:  0.735\n",
      "\tTraining loss:  1.065465154695872\n",
      "\tvalidation loss:  1.0614899302618555\n",
      "epoch # 74 :\n",
      "\tTraining Accuracy:  0.769712140175219\n",
      "\tValidation Accuracy:  0.775\n",
      "\tTraining loss:  1.052000771143931\n",
      "\tvalidation loss:  1.053646064212079\n",
      "epoch # 75 :\n",
      "\tTraining Accuracy:  0.7734668335419274\n",
      "\tValidation Accuracy:  0.78\n",
      "\tTraining loss:  1.0451145131321355\n",
      "\tvalidation loss:  1.0503895973595128\n",
      "epoch # 76 :\n",
      "\tTraining Accuracy:  0.7747183979974969\n",
      "\tValidation Accuracy:  0.775\n",
      "\tTraining loss:  1.0369311153773841\n",
      "\tvalidation loss:  1.0371282311297318\n",
      "epoch # 77 :\n",
      "\tTraining Accuracy:  0.7784730913642053\n",
      "\tValidation Accuracy:  0.775\n",
      "\tTraining loss:  1.031612702868245\n",
      "\tvalidation loss:  1.0339526926742162\n",
      "epoch # 78 :\n",
      "\tTraining Accuracy:  0.7759699624530664\n",
      "\tValidation Accuracy:  0.775\n",
      "\tTraining loss:  1.0241732798207022\n",
      "\tvalidation loss:  1.0228239895896865\n",
      "epoch # 79 :\n",
      "\tTraining Accuracy:  0.785982478097622\n",
      "\tValidation Accuracy:  0.775\n",
      "\tTraining loss:  1.0134600859773635\n",
      "\tvalidation loss:  1.0113233097314014\n",
      "epoch # 80 :\n",
      "\tTraining Accuracy:  0.7709637046307884\n",
      "\tValidation Accuracy:  0.77\n",
      "\tTraining loss:  1.0090043738471528\n",
      "\tvalidation loss:  1.0084103335400334\n",
      "epoch # 81 :\n",
      "\tTraining Accuracy:  0.7772215269086358\n",
      "\tValidation Accuracy:  0.775\n",
      "\tTraining loss:  1.0024996198504699\n",
      "\tvalidation loss:  0.9980032431349036\n",
      "epoch # 82 :\n",
      "\tTraining Accuracy:  0.7909887359198998\n",
      "\tValidation Accuracy:  0.79\n",
      "\tTraining loss:  0.9912303353650955\n",
      "\tvalidation loss:  0.9882137366228158\n",
      "epoch # 83 :\n",
      "\tTraining Accuracy:  0.7772215269086358\n",
      "\tValidation Accuracy:  0.785\n",
      "\tTraining loss:  0.9901437870934934\n",
      "\tvalidation loss:  0.9719219759773503\n",
      "epoch # 84 :\n",
      "\tTraining Accuracy:  0.7784730913642053\n",
      "\tValidation Accuracy:  0.785\n",
      "\tTraining loss:  0.974743706591304\n",
      "\tvalidation loss:  0.9627157438443891\n",
      "epoch # 85 :\n",
      "\tTraining Accuracy:  0.7809762202753442\n",
      "\tValidation Accuracy:  0.775\n",
      "\tTraining loss:  0.966372971290686\n",
      "\tvalidation loss:  0.9545328463534153\n",
      "epoch # 86 :\n",
      "\tTraining Accuracy:  0.785982478097622\n",
      "\tValidation Accuracy:  0.77\n",
      "\tTraining loss:  0.9559103302216728\n",
      "\tvalidation loss:  0.9526652817880157\n",
      "epoch # 87 :\n",
      "\tTraining Accuracy:  0.7984981226533167\n",
      "\tValidation Accuracy:  0.775\n",
      "\tTraining loss:  0.9573019841562037\n",
      "\tvalidation loss:  0.9665663193042398\n",
      "epoch # 88 :\n",
      "\tTraining Accuracy:  0.785982478097622\n",
      "\tValidation Accuracy:  0.775\n",
      "\tTraining loss:  0.9502761688105273\n",
      "\tvalidation loss:  0.9590608504335556\n",
      "epoch # 89 :\n",
      "\tTraining Accuracy:  0.7809762202753442\n",
      "\tValidation Accuracy:  0.765\n",
      "\tTraining loss:  0.9500152662912821\n",
      "\tvalidation loss:  0.9518434657462373\n",
      "epoch # 90 :\n",
      "\tTraining Accuracy:  0.7834793491864831\n",
      "\tValidation Accuracy:  0.775\n",
      "\tTraining loss:  0.9415565789985143\n",
      "\tvalidation loss:  0.9457752534569772\n",
      "epoch # 91 :\n",
      "\tTraining Accuracy:  0.7772215269086358\n",
      "\tValidation Accuracy:  0.79\n",
      "\tTraining loss:  0.9399708128440782\n",
      "\tvalidation loss:  0.9303831920617119\n",
      "epoch # 92 :\n",
      "\tTraining Accuracy:  0.7972465581977471\n",
      "\tValidation Accuracy:  0.8\n",
      "\tTraining loss:  0.9177033167147914\n",
      "\tvalidation loss:  0.9201946293185813\n",
      "epoch # 93 :\n",
      "\tTraining Accuracy:  0.7897371714643304\n",
      "\tValidation Accuracy:  0.78\n",
      "\tTraining loss:  0.913944405163977\n",
      "\tvalidation loss:  0.9207920655319132\n",
      "epoch # 94 :\n",
      "\tTraining Accuracy:  0.7922403003754693\n",
      "\tValidation Accuracy:  0.79\n",
      "\tTraining loss:  0.9105585773376307\n",
      "\tvalidation loss:  0.9019483894719502\n",
      "epoch # 95 :\n",
      "\tTraining Accuracy:  0.7834793491864831\n",
      "\tValidation Accuracy:  0.785\n",
      "\tTraining loss:  0.9051922343196067\n",
      "\tvalidation loss:  0.9039879989597016\n",
      "epoch # 96 :\n",
      "\tTraining Accuracy:  0.7909887359198998\n",
      "\tValidation Accuracy:  0.785\n",
      "\tTraining loss:  0.9029384314332787\n",
      "\tvalidation loss:  0.9044747014911215\n",
      "epoch # 97 :\n",
      "\tTraining Accuracy:  0.8072590738423029\n",
      "\tValidation Accuracy:  0.795\n",
      "\tTraining loss:  0.8916444729737473\n",
      "\tvalidation loss:  0.8946598169536402\n",
      "epoch # 98 :\n",
      "\tTraining Accuracy:  0.8060075093867334\n",
      "\tValidation Accuracy:  0.805\n",
      "\tTraining loss:  0.8861267648282307\n",
      "\tvalidation loss:  0.887146817865305\n",
      "epoch # 99 :\n",
      "\tTraining Accuracy:  0.8035043804755945\n",
      "\tValidation Accuracy:  0.785\n",
      "\tTraining loss:  0.8838047989304758\n",
      "\tvalidation loss:  0.889958821911317\n"
     ]
    }
   ],
   "source": [
    "model.train(Xtr, Ytr, Xva, Yva, epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_va = model.predict(Xva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 9 with 0.23486921237843783 confidence\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num = random.randint(0, len(Xva))\n",
    "plt.imshow(np.reshape(Xva[num], (28,28)))\n",
    "p = predict_va[num]\n",
    "max_index = np.argmax(p)\n",
    "print (\"Predicting\", max_index, \"with\", p[max_index], \"confidence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model = tf.keras.models.Sequential()\n",
    "\n",
    "def create_dense(n):\n",
    "    return tf.keras.layers.Dense(n,\n",
    "                use_bias = False)\n",
    "#                 activation='relu',\n",
    "#                 kernel_initializer=tf.ones_initializer())\n",
    "#               kernel_initializer=tf.random_uniform_initializer(minval=-1, maxval=1))\n",
    "\n",
    "tf_model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "tf_model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "# tf_model.add(tf.keras.layers.Softmax())\n",
    "\n",
    "tf_model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.01),\n",
    "                 loss = tf.keras.losses.categorical_crossentropy,\n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 799 samples, validate on 200 samples\n",
      "Epoch 1/100\n",
      "799/799 [==============================] - 2s 3ms/step - loss: 2.3068 - acc: 0.1289 - val_loss: 2.1881 - val_acc: 0.2200\n",
      "Epoch 2/100\n",
      "799/799 [==============================] - 0s 137us/step - loss: 2.1457 - acc: 0.2553 - val_loss: 2.0468 - val_acc: 0.3750\n",
      "Epoch 3/100\n",
      "799/799 [==============================] - 0s 176us/step - loss: 2.0044 - acc: 0.3842 - val_loss: 1.9067 - val_acc: 0.4800\n",
      "Epoch 4/100\n",
      "799/799 [==============================] - 0s 159us/step - loss: 1.8719 - acc: 0.4793 - val_loss: 1.7774 - val_acc: 0.5650\n",
      "Epoch 5/100\n",
      "799/799 [==============================] - 0s 144us/step - loss: 1.7460 - acc: 0.5457 - val_loss: 1.6481 - val_acc: 0.6250\n",
      "Epoch 6/100\n",
      "799/799 [==============================] - ETA: 0s - loss: 1.6243 - acc: 0.609 - 0s 177us/step - loss: 1.6196 - acc: 0.6108 - val_loss: 1.5188 - val_acc: 0.7000\n",
      "Epoch 7/100\n",
      "799/799 [==============================] - 0s 182us/step - loss: 1.4955 - acc: 0.6733 - val_loss: 1.3926 - val_acc: 0.7550\n",
      "Epoch 8/100\n",
      "799/799 [==============================] - 0s 168us/step - loss: 1.3812 - acc: 0.6984 - val_loss: 1.2800 - val_acc: 0.7900\n",
      "Epoch 9/100\n",
      "799/799 [==============================] - 0s 142us/step - loss: 1.2789 - acc: 0.7359 - val_loss: 1.1804 - val_acc: 0.7950\n",
      "Epoch 10/100\n",
      "799/799 [==============================] - 0s 133us/step - loss: 1.1862 - acc: 0.7522 - val_loss: 1.0932 - val_acc: 0.8200\n",
      "Epoch 11/100\n",
      "799/799 [==============================] - 0s 140us/step - loss: 1.1038 - acc: 0.7835 - val_loss: 1.0159 - val_acc: 0.8200\n",
      "Epoch 12/100\n",
      "799/799 [==============================] - 0s 143us/step - loss: 1.0320 - acc: 0.7935 - val_loss: 0.9497 - val_acc: 0.8200\n",
      "Epoch 13/100\n",
      "799/799 [==============================] - 0s 144us/step - loss: 0.9675 - acc: 0.8098 - val_loss: 0.8949 - val_acc: 0.8350\n",
      "Epoch 14/100\n",
      "799/799 [==============================] - 0s 135us/step - loss: 0.9108 - acc: 0.8210 - val_loss: 0.8433 - val_acc: 0.8300\n",
      "Epoch 15/100\n",
      "799/799 [==============================] - 0s 139us/step - loss: 0.8633 - acc: 0.8285 - val_loss: 0.8034 - val_acc: 0.8400\n",
      "Epoch 16/100\n",
      "799/799 [==============================] - 0s 150us/step - loss: 0.8182 - acc: 0.8385 - val_loss: 0.7627 - val_acc: 0.8550\n",
      "Epoch 17/100\n",
      "799/799 [==============================] - 0s 139us/step - loss: 0.7813 - acc: 0.8436 - val_loss: 0.7251 - val_acc: 0.8600\n",
      "Epoch 18/100\n",
      "799/799 [==============================] - 0s 137us/step - loss: 0.7463 - acc: 0.8486 - val_loss: 0.6986 - val_acc: 0.8650\n",
      "Epoch 19/100\n",
      "799/799 [==============================] - 0s 147us/step - loss: 0.7158 - acc: 0.8461 - val_loss: 0.6699 - val_acc: 0.8700\n",
      "Epoch 20/100\n",
      "799/799 [==============================] - 0s 143us/step - loss: 0.6889 - acc: 0.8548 - val_loss: 0.6454 - val_acc: 0.8700\n",
      "Epoch 21/100\n",
      "799/799 [==============================] - 0s 137us/step - loss: 0.6635 - acc: 0.8636 - val_loss: 0.6241 - val_acc: 0.8700\n",
      "Epoch 22/100\n",
      "799/799 [==============================] - 0s 136us/step - loss: 0.6409 - acc: 0.8673 - val_loss: 0.6068 - val_acc: 0.8750\n",
      "Epoch 23/100\n",
      "799/799 [==============================] - 0s 135us/step - loss: 0.6201 - acc: 0.8711 - val_loss: 0.5900 - val_acc: 0.8750\n",
      "Epoch 24/100\n",
      "799/799 [==============================] - 0s 137us/step - loss: 0.6002 - acc: 0.8711 - val_loss: 0.5748 - val_acc: 0.8750\n",
      "Epoch 25/100\n",
      "799/799 [==============================] - 0s 136us/step - loss: 0.5829 - acc: 0.8748 - val_loss: 0.5622 - val_acc: 0.8850\n",
      "Epoch 26/100\n",
      "799/799 [==============================] - 0s 142us/step - loss: 0.5671 - acc: 0.8773 - val_loss: 0.5455 - val_acc: 0.8900\n",
      "Epoch 27/100\n",
      "799/799 [==============================] - 0s 151us/step - loss: 0.5518 - acc: 0.8836 - val_loss: 0.5353 - val_acc: 0.8900\n",
      "Epoch 28/100\n",
      "799/799 [==============================] - 0s 146us/step - loss: 0.5376 - acc: 0.8824 - val_loss: 0.5216 - val_acc: 0.8850\n",
      "Epoch 29/100\n",
      "799/799 [==============================] - 0s 144us/step - loss: 0.5242 - acc: 0.8836 - val_loss: 0.5132 - val_acc: 0.8850\n",
      "Epoch 30/100\n",
      "799/799 [==============================] - 0s 146us/step - loss: 0.5121 - acc: 0.8961 - val_loss: 0.5041 - val_acc: 0.8850\n",
      "Epoch 31/100\n",
      "799/799 [==============================] - 0s 150us/step - loss: 0.5003 - acc: 0.8961 - val_loss: 0.4965 - val_acc: 0.8900\n",
      "Epoch 32/100\n",
      "799/799 [==============================] - 0s 145us/step - loss: 0.4898 - acc: 0.8961 - val_loss: 0.4871 - val_acc: 0.8850\n",
      "Epoch 33/100\n",
      "799/799 [==============================] - 0s 144us/step - loss: 0.4790 - acc: 0.8986 - val_loss: 0.4810 - val_acc: 0.8850\n",
      "Epoch 34/100\n",
      "799/799 [==============================] - 0s 147us/step - loss: 0.4695 - acc: 0.9024 - val_loss: 0.4721 - val_acc: 0.8900\n",
      "Epoch 35/100\n",
      "799/799 [==============================] - 0s 146us/step - loss: 0.4600 - acc: 0.9061 - val_loss: 0.4672 - val_acc: 0.8850\n",
      "Epoch 36/100\n",
      "799/799 [==============================] - 0s 137us/step - loss: 0.4517 - acc: 0.9049 - val_loss: 0.4586 - val_acc: 0.8950\n",
      "Epoch 37/100\n",
      "799/799 [==============================] - 0s 143us/step - loss: 0.4436 - acc: 0.9061 - val_loss: 0.4514 - val_acc: 0.8950\n",
      "Epoch 38/100\n",
      "799/799 [==============================] - 0s 145us/step - loss: 0.4346 - acc: 0.9074 - val_loss: 0.4472 - val_acc: 0.8900\n",
      "Epoch 39/100\n",
      "799/799 [==============================] - 0s 148us/step - loss: 0.4270 - acc: 0.9099 - val_loss: 0.4411 - val_acc: 0.9000\n",
      "Epoch 40/100\n",
      "799/799 [==============================] - 0s 150us/step - loss: 0.4198 - acc: 0.9149 - val_loss: 0.4349 - val_acc: 0.9050\n",
      "Epoch 41/100\n",
      "799/799 [==============================] - 0s 137us/step - loss: 0.4123 - acc: 0.9149 - val_loss: 0.4313 - val_acc: 0.9000\n",
      "Epoch 42/100\n",
      "799/799 [==============================] - 0s 146us/step - loss: 0.4062 - acc: 0.9149 - val_loss: 0.4270 - val_acc: 0.8950\n",
      "Epoch 43/100\n",
      "799/799 [==============================] - 0s 142us/step - loss: 0.3993 - acc: 0.9186 - val_loss: 0.4244 - val_acc: 0.8900\n",
      "Epoch 44/100\n",
      "799/799 [==============================] - 0s 138us/step - loss: 0.3929 - acc: 0.9136 - val_loss: 0.4218 - val_acc: 0.8950\n",
      "Epoch 45/100\n",
      "799/799 [==============================] - 0s 141us/step - loss: 0.3874 - acc: 0.9199 - val_loss: 0.4148 - val_acc: 0.9000\n",
      "Epoch 46/100\n",
      "799/799 [==============================] - 0s 136us/step - loss: 0.3813 - acc: 0.9237 - val_loss: 0.4117 - val_acc: 0.8950\n",
      "Epoch 47/100\n",
      "799/799 [==============================] - 0s 145us/step - loss: 0.3754 - acc: 0.9199 - val_loss: 0.4095 - val_acc: 0.8950\n",
      "Epoch 48/100\n",
      "799/799 [==============================] - 0s 142us/step - loss: 0.3698 - acc: 0.9312 - val_loss: 0.4085 - val_acc: 0.9000\n",
      "Epoch 49/100\n",
      "799/799 [==============================] - 0s 137us/step - loss: 0.3652 - acc: 0.9299 - val_loss: 0.4030 - val_acc: 0.9000\n",
      "Epoch 50/100\n",
      "799/799 [==============================] - 0s 139us/step - loss: 0.3595 - acc: 0.9274 - val_loss: 0.3976 - val_acc: 0.9000\n",
      "Epoch 51/100\n",
      "799/799 [==============================] - 0s 137us/step - loss: 0.3542 - acc: 0.9324 - val_loss: 0.3953 - val_acc: 0.9000\n",
      "Epoch 52/100\n",
      "799/799 [==============================] - 0s 141us/step - loss: 0.3495 - acc: 0.9324 - val_loss: 0.3945 - val_acc: 0.9000\n",
      "Epoch 53/100\n",
      "799/799 [==============================] - 0s 126us/step - loss: 0.3448 - acc: 0.9362 - val_loss: 0.3924 - val_acc: 0.9000\n",
      "Epoch 54/100\n",
      "799/799 [==============================] - 0s 152us/step - loss: 0.3400 - acc: 0.9349 - val_loss: 0.3888 - val_acc: 0.9000\n",
      "Epoch 55/100\n",
      "799/799 [==============================] - 0s 136us/step - loss: 0.3361 - acc: 0.9374 - val_loss: 0.3861 - val_acc: 0.9000\n",
      "Epoch 56/100\n",
      "799/799 [==============================] - 0s 136us/step - loss: 0.3308 - acc: 0.9362 - val_loss: 0.3844 - val_acc: 0.9050\n",
      "Epoch 57/100\n",
      "799/799 [==============================] - 0s 134us/step - loss: 0.3270 - acc: 0.9374 - val_loss: 0.3816 - val_acc: 0.9000\n",
      "Epoch 58/100\n",
      "799/799 [==============================] - 0s 139us/step - loss: 0.3230 - acc: 0.9349 - val_loss: 0.3783 - val_acc: 0.9050\n",
      "Epoch 59/100\n",
      "799/799 [==============================] - 0s 137us/step - loss: 0.3185 - acc: 0.9374 - val_loss: 0.3772 - val_acc: 0.9000\n",
      "Epoch 60/100\n",
      "799/799 [==============================] - 0s 134us/step - loss: 0.3151 - acc: 0.9399 - val_loss: 0.3774 - val_acc: 0.9050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "799/799 [==============================] - 0s 137us/step - loss: 0.3110 - acc: 0.9399 - val_loss: 0.3718 - val_acc: 0.9050\n",
      "Epoch 62/100\n",
      "799/799 [==============================] - 0s 137us/step - loss: 0.3068 - acc: 0.9412 - val_loss: 0.3722 - val_acc: 0.9050\n",
      "Epoch 63/100\n",
      "799/799 [==============================] - 0s 133us/step - loss: 0.3036 - acc: 0.9412 - val_loss: 0.3702 - val_acc: 0.9050\n",
      "Epoch 64/100\n",
      "799/799 [==============================] - 0s 133us/step - loss: 0.2994 - acc: 0.9437 - val_loss: 0.3657 - val_acc: 0.9050\n",
      "Epoch 65/100\n",
      "799/799 [==============================] - 0s 141us/step - loss: 0.2958 - acc: 0.9424 - val_loss: 0.3658 - val_acc: 0.9050\n",
      "Epoch 66/100\n",
      "799/799 [==============================] - 0s 141us/step - loss: 0.2928 - acc: 0.9437 - val_loss: 0.3637 - val_acc: 0.9050\n",
      "Epoch 67/100\n",
      "799/799 [==============================] - 0s 139us/step - loss: 0.2895 - acc: 0.9412 - val_loss: 0.3619 - val_acc: 0.9050\n",
      "Epoch 68/100\n",
      "799/799 [==============================] - 0s 139us/step - loss: 0.2858 - acc: 0.9462 - val_loss: 0.3610 - val_acc: 0.9050\n",
      "Epoch 69/100\n",
      "799/799 [==============================] - 0s 136us/step - loss: 0.2825 - acc: 0.9474 - val_loss: 0.3613 - val_acc: 0.9100\n",
      "Epoch 70/100\n",
      "799/799 [==============================] - 0s 124us/step - loss: 0.2797 - acc: 0.9449 - val_loss: 0.3585 - val_acc: 0.9050\n",
      "Epoch 71/100\n",
      "799/799 [==============================] - 0s 151us/step - loss: 0.2760 - acc: 0.9449 - val_loss: 0.3564 - val_acc: 0.9050\n",
      "Epoch 72/100\n",
      "799/799 [==============================] - 0s 136us/step - loss: 0.2734 - acc: 0.9499 - val_loss: 0.3562 - val_acc: 0.9050\n",
      "Epoch 73/100\n",
      "799/799 [==============================] - 0s 136us/step - loss: 0.2704 - acc: 0.9474 - val_loss: 0.3549 - val_acc: 0.9050\n",
      "Epoch 74/100\n",
      "799/799 [==============================] - 0s 135us/step - loss: 0.2670 - acc: 0.9474 - val_loss: 0.3523 - val_acc: 0.9050\n",
      "Epoch 75/100\n",
      "799/799 [==============================] - 0s 136us/step - loss: 0.2639 - acc: 0.9562 - val_loss: 0.3537 - val_acc: 0.9100\n",
      "Epoch 76/100\n",
      "799/799 [==============================] - 0s 138us/step - loss: 0.2613 - acc: 0.9499 - val_loss: 0.3517 - val_acc: 0.9050\n",
      "Epoch 77/100\n",
      "799/799 [==============================] - 0s 135us/step - loss: 0.2583 - acc: 0.9499 - val_loss: 0.3488 - val_acc: 0.9050\n",
      "Epoch 78/100\n",
      "799/799 [==============================] - 0s 134us/step - loss: 0.2553 - acc: 0.9537 - val_loss: 0.3490 - val_acc: 0.9050\n",
      "Epoch 79/100\n",
      "799/799 [==============================] - 0s 138us/step - loss: 0.2528 - acc: 0.9524 - val_loss: 0.3460 - val_acc: 0.9050\n",
      "Epoch 80/100\n",
      "799/799 [==============================] - 0s 136us/step - loss: 0.2502 - acc: 0.9537 - val_loss: 0.3453 - val_acc: 0.9050\n",
      "Epoch 81/100\n",
      "799/799 [==============================] - 0s 142us/step - loss: 0.2476 - acc: 0.9549 - val_loss: 0.3427 - val_acc: 0.9050\n",
      "Epoch 82/100\n",
      "799/799 [==============================] - 0s 135us/step - loss: 0.2452 - acc: 0.9587 - val_loss: 0.3439 - val_acc: 0.9050\n",
      "Epoch 83/100\n",
      "799/799 [==============================] - 0s 140us/step - loss: 0.2428 - acc: 0.9587 - val_loss: 0.3453 - val_acc: 0.9050\n",
      "Epoch 84/100\n",
      "799/799 [==============================] - 0s 166us/step - loss: 0.2404 - acc: 0.9612 - val_loss: 0.3431 - val_acc: 0.9050\n",
      "Epoch 85/100\n",
      "799/799 [==============================] - 0s 158us/step - loss: 0.2375 - acc: 0.9612 - val_loss: 0.3399 - val_acc: 0.9050\n",
      "Epoch 86/100\n",
      "799/799 [==============================] - 0s 144us/step - loss: 0.2350 - acc: 0.9599 - val_loss: 0.3395 - val_acc: 0.9050\n",
      "Epoch 87/100\n",
      "799/799 [==============================] - 0s 144us/step - loss: 0.2326 - acc: 0.9587 - val_loss: 0.3405 - val_acc: 0.9050\n",
      "Epoch 88/100\n",
      "799/799 [==============================] - 0s 137us/step - loss: 0.2304 - acc: 0.9625 - val_loss: 0.3391 - val_acc: 0.9050\n",
      "Epoch 89/100\n",
      "799/799 [==============================] - 0s 142us/step - loss: 0.2277 - acc: 0.9650 - val_loss: 0.3397 - val_acc: 0.9050\n",
      "Epoch 90/100\n",
      "799/799 [==============================] - 0s 157us/step - loss: 0.2261 - acc: 0.9650 - val_loss: 0.3390 - val_acc: 0.9100\n",
      "Epoch 91/100\n",
      "799/799 [==============================] - 0s 163us/step - loss: 0.2237 - acc: 0.9625 - val_loss: 0.3380 - val_acc: 0.9100\n",
      "Epoch 92/100\n",
      "799/799 [==============================] - 0s 140us/step - loss: 0.2208 - acc: 0.9625 - val_loss: 0.3388 - val_acc: 0.9100\n",
      "Epoch 93/100\n",
      "799/799 [==============================] - 0s 141us/step - loss: 0.2189 - acc: 0.9637 - val_loss: 0.3341 - val_acc: 0.9050\n",
      "Epoch 94/100\n",
      "799/799 [==============================] - 0s 147us/step - loss: 0.2166 - acc: 0.9650 - val_loss: 0.3350 - val_acc: 0.9100\n",
      "Epoch 95/100\n",
      "799/799 [==============================] - 0s 140us/step - loss: 0.2148 - acc: 0.9650 - val_loss: 0.3346 - val_acc: 0.9050\n",
      "Epoch 96/100\n",
      "799/799 [==============================] - 0s 136us/step - loss: 0.2126 - acc: 0.9650 - val_loss: 0.3338 - val_acc: 0.9050\n",
      "Epoch 97/100\n",
      "799/799 [==============================] - 0s 142us/step - loss: 0.2104 - acc: 0.9675 - val_loss: 0.3304 - val_acc: 0.9000\n",
      "Epoch 98/100\n",
      "799/799 [==============================] - 0s 155us/step - loss: 0.2090 - acc: 0.9662 - val_loss: 0.3319 - val_acc: 0.9050\n",
      "Epoch 99/100\n",
      "799/799 [==============================] - 0s 154us/step - loss: 0.2063 - acc: 0.9662 - val_loss: 0.3316 - val_acc: 0.9050\n",
      "Epoch 100/100\n",
      "799/799 [==============================] - 0s 155us/step - loss: 0.2046 - acc: 0.9675 - val_loss: 0.3301 - val_acc: 0.9000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x139baff1c88>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_model.fit(Xtr, Ytr, validation_data=(Xva, Yva), epochs = 100, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
