{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "    import imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import NeuralNetwork as nn\n",
    "import numpy as np\n",
    "from sklearn import *\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caojo\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\caojo\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\caojo\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\caojo\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\caojo\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\caojo\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(999, 785)\n"
     ]
    }
   ],
   "source": [
    "data = np.genfromtxt(\"data/train_small.csv\", delimiter=\",\", skip_header=1, dtype=float)\n",
    "# data = data[:50]\n",
    "# data = np.genfromtxt(\"data/generated_dataset.csv\", delimiter=\",\", skip_header=1, dtype=float)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(999, 28, 28, 1)\n",
      "(999,)\n"
     ]
    }
   ],
   "source": [
    "X = data[:,1:]\n",
    "X = X.reshape((X.shape[0],28,28,1))\n",
    "Y = data[:,0]\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(999, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "X /= np.max(X)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(999, 10)\n"
     ]
    }
   ],
   "source": [
    "Y = Y.astype(dtype=int)\n",
    "tempY = np.zeros(shape=(len(Y), np.max(Y)+1))\n",
    "tempY[np.arange(len(Y)),Y] = 1\n",
    "Y = tempY\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train/validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(799, 28, 28, 1)\n",
      "(799, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caojo\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "Xtr, Xva, Ytr, Yva = model_selection.train_test_split(X, Y, train_size=.80, random_state=0)\n",
    "\n",
    "print(Xtr.shape)\n",
    "print(Ytr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.NeuralNetwork(input_shape = Xtr.shape[1:], lr=0.01, loss=nn.LossFunction.CrossEntropy())\n",
    "model.add_layer(nn.Layer.ConvolutionalLayer, filter_size = (2,2), num_filters = 8)\n",
    "model.add_layer(nn.Layer.Relu)\n",
    "model.add_layer(nn.Layer.FlattenLayer)\n",
    "model.add_layer(nn.Layer.FullyConnectedLayer, num_neurons = 32)\n",
    "model.add_layer(nn.Layer.Relu)\n",
    "model.add_layer(nn.Layer.FullyConnectedLayer, num_neurons = 10)\n",
    "model.add_layer(nn.Layer.Softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch # 0 :\n",
      "\tTraining Accuracy:  0.7884856070087609\n",
      "\tValidation Accuracy:  0.83\n",
      "\tTraining loss:  0.9271221094736484\n",
      "\tvalidation loss:  0.8840913774425303\n",
      "epoch # 1 :\n",
      "\tTraining Accuracy:  0.7847309136420526\n",
      "\tValidation Accuracy:  0.83\n",
      "\tTraining loss:  0.934136387245821\n",
      "\tvalidation loss:  0.889030765822655\n",
      "epoch # 2 :\n",
      "\tTraining Accuracy:  0.772215269086358\n",
      "\tValidation Accuracy:  0.79\n",
      "\tTraining loss:  0.9107748453667767\n",
      "\tvalidation loss:  0.9153697659234606\n",
      "epoch # 3 :\n",
      "\tTraining Accuracy:  0.804755944931164\n",
      "\tValidation Accuracy:  0.79\n",
      "\tTraining loss:  0.876187713987238\n",
      "\tvalidation loss:  0.8718047862932401\n",
      "epoch # 4 :\n",
      "\tTraining Accuracy:  0.8122653316645807\n",
      "\tValidation Accuracy:  0.835\n",
      "\tTraining loss:  0.868056459899386\n",
      "\tvalidation loss:  0.8491949986566134\n",
      "epoch # 5 :\n",
      "\tTraining Accuracy:  0.818523153942428\n",
      "\tValidation Accuracy:  0.835\n",
      "\tTraining loss:  0.8294957735972528\n",
      "\tvalidation loss:  0.8011683660943502\n",
      "epoch # 6 :\n",
      "\tTraining Accuracy:  0.8247809762202754\n",
      "\tValidation Accuracy:  0.87\n",
      "\tTraining loss:  0.8186099897276405\n",
      "\tvalidation loss:  0.7858721045661458\n",
      "epoch # 7 :\n",
      "\tTraining Accuracy:  0.8172715894868585\n",
      "\tValidation Accuracy:  0.795\n",
      "\tTraining loss:  0.8387141847348282\n",
      "\tvalidation loss:  0.839681031897091\n",
      "epoch # 8 :\n",
      "\tTraining Accuracy:  0.8072590738423029\n",
      "\tValidation Accuracy:  0.8\n",
      "\tTraining loss:  0.8223833682685266\n",
      "\tvalidation loss:  0.8006729297952426\n",
      "epoch # 9 :\n",
      "\tTraining Accuracy:  0.8260325406758448\n",
      "\tValidation Accuracy:  0.82\n",
      "\tTraining loss:  0.7833091482250182\n",
      "\tvalidation loss:  0.8012463698819556\n",
      "epoch # 10 :\n",
      "\tTraining Accuracy:  0.8448060075093867\n",
      "\tValidation Accuracy:  0.815\n",
      "\tTraining loss:  0.7606120880829487\n",
      "\tvalidation loss:  0.7721680805009228\n",
      "epoch # 11 :\n",
      "\tTraining Accuracy:  0.8297872340425532\n",
      "\tValidation Accuracy:  0.785\n",
      "\tTraining loss:  0.7894732593037963\n",
      "\tvalidation loss:  0.8374191815833121\n",
      "epoch # 12 :\n",
      "\tTraining Accuracy:  0.8435544430538173\n",
      "\tValidation Accuracy:  0.85\n",
      "\tTraining loss:  0.7385353511696011\n",
      "\tvalidation loss:  0.7369453332344071\n",
      "epoch # 13 :\n",
      "\tTraining Accuracy:  0.8460575719649562\n",
      "\tValidation Accuracy:  0.85\n",
      "\tTraining loss:  0.7243593089570408\n",
      "\tvalidation loss:  0.7173613522760094\n",
      "epoch # 14 :\n",
      "\tTraining Accuracy:  0.8222778473091364\n",
      "\tValidation Accuracy:  0.82\n",
      "\tTraining loss:  0.7522746311571225\n",
      "\tvalidation loss:  0.7471425149788183\n",
      "epoch # 15 :\n",
      "\tTraining Accuracy:  0.8523153942428036\n",
      "\tValidation Accuracy:  0.835\n",
      "\tTraining loss:  0.7058594794685592\n",
      "\tvalidation loss:  0.7009238275242816\n",
      "epoch # 16 :\n",
      "\tTraining Accuracy:  0.8498122653316645\n",
      "\tValidation Accuracy:  0.835\n",
      "\tTraining loss:  0.6930860760107403\n",
      "\tvalidation loss:  0.6916771543235618\n",
      "epoch # 17 :\n",
      "\tTraining Accuracy:  0.8272841051314143\n",
      "\tValidation Accuracy:  0.775\n",
      "\tTraining loss:  0.7143994310793056\n",
      "\tvalidation loss:  0.7368341882971514\n",
      "epoch # 18 :\n",
      "\tTraining Accuracy:  0.8285356695869838\n",
      "\tValidation Accuracy:  0.805\n",
      "\tTraining loss:  0.720407272503502\n",
      "\tvalidation loss:  0.7351146388719164\n",
      "epoch # 19 :\n",
      "\tTraining Accuracy:  0.8448060075093867\n",
      "\tValidation Accuracy:  0.83\n",
      "\tTraining loss:  0.680619456803517\n",
      "\tvalidation loss:  0.682006845054753\n"
     ]
    }
   ],
   "source": [
    "model.train(Xtr, Ytr, Xva, Yva, epochs=20, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_va = model.predict(Xva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 5 with 0.11425996444845025 confidence\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num = random.randint(0, len(Xva))\n",
    "plt.imshow(np.reshape(Xva[num], (28,28)))\n",
    "p = predict_va[num]\n",
    "max_index = np.argmax(p)\n",
    "print (\"Predicting\", max_index, \"with\", p[max_index], \"confidence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model = tf.keras.models.Sequential()\n",
    "tf_model.add(tf.layers.Conv2D(8, (2, 2), input_shape=(28, 28, 1),  activation=tf.nn.relu))\n",
    "tf_model.add(tf.layers.Flatten())\n",
    "tf_model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "tf_model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "tf_model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.01),\n",
    "                 loss = tf.keras.losses.categorical_crossentropy,\n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 799 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "799/799 [==============================] - 1s 718us/step - loss: 2.1445 - acc: 0.2691 - val_loss: 1.9195 - val_acc: 0.4400\n",
      "Epoch 2/20\n",
      "799/799 [==============================] - 0s 241us/step - loss: 1.8018 - acc: 0.5494 - val_loss: 1.5797 - val_acc: 0.6500\n",
      "Epoch 3/20\n",
      "799/799 [==============================] - 0s 228us/step - loss: 1.4956 - acc: 0.6696 - val_loss: 1.2690 - val_acc: 0.7600\n",
      "Epoch 4/20\n",
      "799/799 [==============================] - 0s 232us/step - loss: 1.2201 - acc: 0.7272 - val_loss: 1.0165 - val_acc: 0.7700\n",
      "Epoch 5/20\n",
      "799/799 [==============================] - 0s 227us/step - loss: 1.0001 - acc: 0.7484 - val_loss: 0.8461 - val_acc: 0.8000\n",
      "Epoch 6/20\n",
      "799/799 [==============================] - 0s 226us/step - loss: 0.8268 - acc: 0.7847 - val_loss: 0.7099 - val_acc: 0.8200\n",
      "Epoch 7/20\n",
      "799/799 [==============================] - 0s 228us/step - loss: 0.7038 - acc: 0.8173 - val_loss: 0.6160 - val_acc: 0.8600\n",
      "Epoch 8/20\n",
      "799/799 [==============================] - 0s 222us/step - loss: 0.6185 - acc: 0.8461 - val_loss: 0.5553 - val_acc: 0.8650\n",
      "Epoch 9/20\n",
      "799/799 [==============================] - 0s 221us/step - loss: 0.5585 - acc: 0.8511 - val_loss: 0.4988 - val_acc: 0.8800\n",
      "Epoch 10/20\n",
      "799/799 [==============================] - 0s 224us/step - loss: 0.5020 - acc: 0.8723 - val_loss: 0.4837 - val_acc: 0.8550\n",
      "Epoch 11/20\n",
      "799/799 [==============================] - 0s 226us/step - loss: 0.4648 - acc: 0.8748 - val_loss: 0.4381 - val_acc: 0.8700\n",
      "Epoch 12/20\n",
      "799/799 [==============================] - 0s 228us/step - loss: 0.4295 - acc: 0.8949 - val_loss: 0.4307 - val_acc: 0.8850\n",
      "Epoch 13/20\n",
      "799/799 [==============================] - 0s 222us/step - loss: 0.4013 - acc: 0.8861 - val_loss: 0.4039 - val_acc: 0.8600\n",
      "Epoch 14/20\n",
      "799/799 [==============================] - 0s 224us/step - loss: 0.3753 - acc: 0.8961 - val_loss: 0.4260 - val_acc: 0.8450\n",
      "Epoch 15/20\n",
      "799/799 [==============================] - 0s 225us/step - loss: 0.3631 - acc: 0.8949 - val_loss: 0.3858 - val_acc: 0.8950\n",
      "Epoch 16/20\n",
      "799/799 [==============================] - 0s 238us/step - loss: 0.3341 - acc: 0.9174 - val_loss: 0.3867 - val_acc: 0.8900\n",
      "Epoch 17/20\n",
      "799/799 [==============================] - 0s 234us/step - loss: 0.3120 - acc: 0.9212 - val_loss: 0.3781 - val_acc: 0.8850\n",
      "Epoch 18/20\n",
      "799/799 [==============================] - 0s 227us/step - loss: 0.2981 - acc: 0.9212 - val_loss: 0.3535 - val_acc: 0.9000\n",
      "Epoch 19/20\n",
      "799/799 [==============================] - 0s 223us/step - loss: 0.2846 - acc: 0.9262 - val_loss: 0.3726 - val_acc: 0.8850\n",
      "Epoch 20/20\n",
      "799/799 [==============================] - 0s 225us/step - loss: 0.2743 - acc: 0.9199 - val_loss: 0.3391 - val_acc: 0.9050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x24d0572ec88>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_model.fit(Xtr, Ytr, validation_data=(Xva, Yva), epochs = 20, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_predict_va = tf_model.predict(Xva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 6 with 0.98584044 confidence\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num = random.randint(0, len(Xva))\n",
    "plt.imshow(np.reshape(Xva[num], (28,28)))\n",
    "p = tf_predict_va[num]\n",
    "max_index = np.argmax(p)\n",
    "print (\"Predicting\", max_index, \"with\", p[max_index], \"confidence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
